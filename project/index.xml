<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Projects | Manuel Pagliuca</title><link>https://manuelpagliuca.github.io/project/</link><atom:link href="https://manuelpagliuca.github.io/project/index.xml" rel="self" type="application/rss+xml"/><description>Projects</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 26 Dec 2023 14:17:20 +0000</lastBuildDate><image><url>https://manuelpagliuca.github.io/media/icon_hu4a5b1b591c5ae08b60d2e1d27385e465_426_512x512_fill_lanczos_center_3.png</url><title>Projects</title><link>https://manuelpagliuca.github.io/project/</link></image><item><title>Design Patterns in C++</title><link>https://manuelpagliuca.github.io/project/design-patterns/</link><pubDate>Tue, 26 Dec 2023 14:17:20 +0000</pubDate><guid>https://manuelpagliuca.github.io/project/design-patterns/</guid><description>&lt;p>Personal project, December 2023&lt;/p>
&lt;p>Between November and December, I wanted to dive deeper into software engineering, so I decided to study and implement some design patterns. In particular the fundamental ones from the &lt;em>Gang of Four&lt;/em> (GoF).&lt;/p>
&lt;p>I created a &lt;a href="https://github.com/manuelpagliuca/design-patterns-cpp" target="_blank" rel="noopener">repository&lt;/a> that serves as a collection of C++ implementations of these patterns. All the GoF patterns are present, but in the future I plan to add the &amp;ldquo;extra&amp;rdquo; patterns as well (currently only the &lt;em>null object&lt;/em> is included).&lt;/p>
&lt;h2 id="creational">Creational&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Design Pattern&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Abstract Factory&lt;/td>
&lt;td>Provides an interface for creating families of related or dependent objects without specifying their concrete classes.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Builder&lt;/td>
&lt;td>Separates the construction of a complex object from its representation, allowing the same construction process to create different representations.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Factory Method&lt;/td>
&lt;td>Defines an interface for creating an object but leaves the choice of its type to the subclasses.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Prototype&lt;/td>
&lt;td>Creates new objects by copying an existing object, known as the prototype.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Singleton&lt;/td>
&lt;td>Ensures a class has only one instance and provides a global point of access to that instance.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="structural">Structural&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Design Pattern&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Adapter&lt;/td>
&lt;td>Allows classes with incompatible interfaces to work together by wrapping its own interface around that of an already existing class.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Bridge&lt;/td>
&lt;td>Decouples an abstraction from its implementation so that the two can vary independently.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Composite&lt;/td>
&lt;td>Composes zero-or-more similar objects so that they can be manipulated as one object.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Decorator&lt;/td>
&lt;td>Dynamically adds/overrides behavior in an existing method of an object.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Facade&lt;/td>
&lt;td>Provides a simplified interface to a large body of code.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Flyweight&lt;/td>
&lt;td>Reduces the cost of creating and manipulating a large number of similar objects.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Proxy&lt;/td>
&lt;td>Provides a placeholder for another object to control access, reduce cost, and reduce complexity.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="behavioral">Behavioral&lt;/h2>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Design Pattern&lt;/th>
&lt;th>Description&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>Chain of Responsibility&lt;/td>
&lt;td>Delegates commands to a chain of processing objects.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Command&lt;/td>
&lt;td>Creates objects that encapsulate actions and parameters.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Interpreter&lt;/td>
&lt;td>Implements a specialized language.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Iterator&lt;/td>
&lt;td>Accesses the elements of an object sequentially without exposing its underlying representation.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Mediator&lt;/td>
&lt;td>Allows loose coupling between classes by being the only class that has detailed knowledge of their methods.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Memento&lt;/td>
&lt;td>Provides the ability to restore an object to its previous state (undo).&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Observer&lt;/td>
&lt;td>Is a publish/subscribe pattern, which allows some observer objects to see an event.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>State&lt;/td>
&lt;td>Allows an object to alter its behavior when its internal state changes.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Strategy&lt;/td>
&lt;td>Allows one of a family of algorithms to be selected on-the-fly at runtime.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Template Method&lt;/td>
&lt;td>Defines the skeleton of an algorithm as an abstract class, allowing its subclasses to provide concrete behavior.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>Visitor&lt;/td>
&lt;td>Separates an algorithm from an object structure by moving the hierarchy of methods into one object.&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>During this exploration, I discovered many interesting aspects of software engineering, especially the concept of scope-level design patterns. Some design patterns can be applied directly to the codebase (code level, or micro), such as the GoF patterns or &lt;em>concurrency patterns&lt;/em> for multi-threaded paradigms.&lt;/p>
&lt;p>Other design patterns act on a higher level of abstraction, and these are called &lt;strong>architectural patterns&lt;/strong>. Some of them are widely known, such as MVC (Model-View-Controller) or n-tier architecture, but most are new to me.&lt;/p>
&lt;p>In the future, I would like to write a blog post about them with diagrams and explanations. It seems like a good idea for studying them in a fun way ðŸ˜&lt;/p></description></item><item><title>Efficient representations of highâ€‘resolution polygonal surfaces, adding anisotropy control to the Microâ€‘Mesh schema</title><link>https://manuelpagliuca.github.io/project/anisotropic-mm/</link><pubDate>Wed, 25 Oct 2023 09:42:00 +0000</pubDate><guid>https://manuelpagliuca.github.io/project/anisotropic-mm/</guid><description>&lt;p>Master&amp;rsquo;s Thesis, October 2023, M.Sc. in Computer Science @UniMI&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/project/anisotropic-mm/dragon_render_huf8cfb674e3e9d5aaba137dd8763e6e91_6565607_6a9b7e8c34208890c54153e224093422.webp 400w,
/project/anisotropic-mm/dragon_render_huf8cfb674e3e9d5aaba137dd8763e6e91_6565607_be20a4681937039f09773afed417acd7.webp 760w,
/project/anisotropic-mm/dragon_render_huf8cfb674e3e9d5aaba137dd8763e6e91_6565607_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://manuelpagliuca.github.io/project/anisotropic-mm/dragon_render_huf8cfb674e3e9d5aaba137dd8763e6e91_6565607_6a9b7e8c34208890c54153e224093422.webp"
width="760"
height="530"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="abstractuploadsabstract_master_s_thesis__en_pdf">&lt;a href="https://manuelpagliuca.github.io/uploads/Abstract_Master_s_Thesis__en_.pdf">Abstract&lt;/a>&lt;/h3>
&lt;p>This &lt;a href="https://manuelpagliuca.github.io/uploads/MANUEL_PAGLIUCA_ANISOTROPIC_MM_Master_s_Thesis__Integral_.pdf">thesis&lt;/a> aims to empirically investigate the imaginable performance for data structures suitable for effectively representing extreme-resolution 3D polygonal surfaces designed for multi-resolution rendering on GPUs.&lt;/p>
&lt;p>To this end, supporting algorithms will be designed, implemented, and tested that transform &amp;ldquo;traditional&amp;rdquo; (i.e., indexed) high-resolution triangular meshes into the analyzed data structures, and then measure the approximation errors introduced through appropriate geometric measurements.&lt;/p>
&lt;p>Other alternative schemes will be studied, which are considered variants of the so-called &amp;ldquo;micro-meshes&amp;rdquo; scheme offered by the latest generation of vendor-specific GPU hardware. These data structures are characterized by the use of a semi-regular subdivision of a medium-resolution &amp;ldquo;base mesh,&amp;rdquo; followed by displacement of the generated vertices. Variants introduced may include the adoption of an anisotropic subdivision step, the adoption of an irregular recursive subdivision scheme, or others.&lt;/p>
&lt;h2 id="dependencies">Dependencies&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.qt.io/" target="_blank" rel="noopener">Qt&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://glm.g-truc.net/0.9.9/index.html" target="_blank" rel="noopener">OpenGL Mathematics&lt;/a>
&lt;ul>
&lt;li>The headers are placed in the directory &lt;code>Dependencies\GLM&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="https://pymeshlab.readthedocs.io/en/latest/installation.html" target="_blank" rel="noopener">PyMeshLab&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="sample-models">Sample models&lt;/h2>
&lt;p>As sample models in this repository, I&amp;rsquo;ve prepared different versions of &lt;a href="https://free3d.com/3d-model/pallas-cat-v1--576987.html" target="_blank" rel="noopener">Pallas Cat&lt;/a> by &lt;em>printable_models&lt;/em>&lt;/p>
&lt;h2 id="python-script-empirical-analysis">Python script (empirical analysis)&lt;/h2>
&lt;p>Executing this script will generate &lt;strong>n&lt;/strong> samples for both subdivision schemes (current and variant). A table (as a text file) containing the face quality values (according to the inradius/circumradius metric) will be built for both batches of samples.&lt;/p>
&lt;p>The table will be ordered by a factor &lt;strong>F&lt;/strong> used, this will allow the comparison of one sample of a table with a sample of the other table, the factor modulates the intensity of subdivisions.&lt;/p>
&lt;p>In the &lt;a href="https://manuelpagliuca.github.io/uploads/MANUEL_PAGLIUCA_ANISOTROPIC_MM_Master_s_Thesis__Integral_.pdf" target="_blank" rel="noopener">thesis&lt;/a>, the comparison is also described using the face area coefficent of variation&lt;/p>
&lt;p>The commands generate two batches of samples, and multiple executions of the commands are used for the analysis since multiple models are tested.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-batch" data-lang="batch">&lt;span class="line">&lt;span class="cl">python face-stats.py --base-mesh=base.obj --target-mesh=target.obj
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Default values if you &lt;em>omit&lt;/em> some of the options:&lt;/p>
&lt;ul>
&lt;li>&lt;code>--base-mesh = pallas_124.obj&lt;/code>&lt;/li>
&lt;li>&lt;code>--target-mesh = pallas_5000.obj&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="graphical-user-interface">Graphical User Interface&lt;/h2>
&lt;h3 id="sample-loading">Sample loading&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt=""
src="https://manuelpagliuca.github.io/project/anisotropic-mm/sample_loading.gif"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="scheme-subdivisions">Scheme subdivisions&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt=""
src="https://manuelpagliuca.github.io/project/anisotropic-mm/subdivisions.gif"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h4 id="displacement">Displacement&lt;/h4>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt=""
src="https://manuelpagliuca.github.io/project/anisotropic-mm/displacement.gif"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="cli-commands">CLI commands&lt;/h3>
&lt;h4 id="generate-a-single-subdivided-sample">Generate a single subdivided sample&lt;/h4>
&lt;p>&lt;strong>Exports&lt;/strong> the given base mesh&amp;rsquo;s subdivided (not displaced) mesh.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-cmd" data-lang="cmd">&lt;span class="line">&lt;span class="cl">anisotropic-micromesh.exe --base-mesh=base.obj --microfaces=100
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>In this example the base mesh is being subdivided by the amount of micro-faces passed (&lt;code>F&lt;/code> can&amp;rsquo;t be passed, since it works in function of the target mesh) using the current scheme (&amp;ldquo;isotropic&amp;rdquo; scheme).&lt;/p>
&lt;/blockquote>
&lt;h4 id="generate-sample">Generate sample&lt;/h4>
&lt;p>&lt;strong>Exports&lt;/strong> the subdivided and displaced mesh given the inputs&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-cmd" data-lang="cmd">&lt;span class="line">&lt;span class="cl">anisotropic_micromesh.exe gen-sample --base-mesh=base.obj --target=target.obj --scheme=aniso --factor=3.5
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>In this example the base mesh will be subdivided using the &lt;code>anisotropic&lt;/code> subdivision scheme, with a factor &lt;code>F=3.5&lt;/code> (subdividing x3.5 times the faces of the target mesh).&lt;/p>
&lt;/blockquote></description></item><item><title>CUDA Ray Tracer</title><link>https://manuelpagliuca.github.io/project/rt/</link><pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate><guid>https://manuelpagliuca.github.io/project/rt/</guid><description>&lt;p>GPU Computing Course, July 2021, M.Sc. in Computer Science @UniMi&lt;/p>
&lt;h2 id="about-the-project">About the project&lt;/h2>
&lt;p>During the &lt;strong>GPU Computing&lt;/strong> course, I decided to implement my old version of the Ray Tracer (based on
&lt;em>Ray Tracing in One
Weekend&lt;/em> by
&lt;a href="https://raytracing.github.io/books/RayTracingInOneWeekend.html" target="_blank">Peter Shirley&lt;/a>
)
in &lt;strong>CUDA&lt;/strong>. In
&lt;a href="https://manuelpagliuca.github.io/uploads/GPU_COMPUTING___RAY_TRACER.pdf" target="_blank">this&lt;/a>
paper I compared
the two Ray Tracers underlining the
huge differences in rendering speed (even without achieving the best warp efficiency).&lt;br>&lt;br>
For the comparison I used the same scene in both the implementation composed by 8 different spheres with
different
materials between &lt;em>lambertian&lt;/em>, &lt;em>metal&lt;/em> and &lt;em>dielectrics&lt;/em>. I highly recommend to check the comparisons
and metrics at the end of the paper, the GitHub repository is at
&lt;a href="https://github.com/manuelpagliuca/Ray-Tracer-CUDA" target="_blank">this&lt;/a>
link if you want to see some
render just download
&lt;a href="https://manuelpagliuca.github.io/uploads/GPU_COMPUTING_RENDERS.zip">this&lt;/a>
zip.&lt;/p></description></item><item><title>Deferred renderer</title><link>https://manuelpagliuca.github.io/project/render/</link><pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate><guid>https://manuelpagliuca.github.io/project/render/</guid><description>&lt;p>Real-Time Graphics Programming Course, July 2021, M.Sc. in Computer Science @UniMi&lt;/p>
&lt;h2 id="about-the-project">About the project&lt;/h2>
&lt;p>This was a project I made for the course of Real-time Graphics Programming. The course provided extensive knowledge about real-time computer graphics. (You can check the
&lt;a href="https://manuelpagliuca.github.io/uploads/Appunti_RTGP.pdf" target="_blank">notes&lt;/a>
I took.) At the end of the course, in addition to an oral exam, there was a project related to graphic programming to be developed with OpenGL. I asked Prof. Gadia if there was the possibility of developing it with Vulkan, he granted me the possibility to take this extra-step, it was very tiring but fruitful from the point of view of learning.&lt;/p>
&lt;p>The project consists in a deferred renderer to improve the overall efficiency of the application in the usage of lights. The scene is composed of three models of the same character, a floor and twenty lights (whose movement and color can be modified), there is the
&lt;a href="https://manuelpagliuca.github.io/uploads/DEFERRED_RENDERING___RTGP.pdf" target="_blank">notes&lt;/a>
containing the various metrics obtained using a different number of lights. The GitHub repository is accessible at
&lt;a href="https://github.com/manuelpagliuca/Vulkan-Deferred-Renderer" target="_blank">this&lt;/a>
link.&lt;/p></description></item><item><title>Fix-It, Stream processing on event-driven system for managing public disservices</title><link>https://manuelpagliuca.github.io/project/fix-it/</link><pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate><guid>https://manuelpagliuca.github.io/project/fix-it/</guid><description>&lt;p>Bachelor&amp;rsquo;s Thesis, December 2019, B.Sc. in Computer Science @UniUPO&lt;/p>
&lt;h2 id="about-the-thesis">About the thesis&lt;/h2>
&lt;p>
&lt;figure id="figure-how-the-flags-are-shown-on-the-map">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="How the flags are shown on the map." srcset="
/project/fix-it/img_hu4a47e7bb555165f3249c1881edac94ca_100119_b37034bddf09116b1976a55737d309a8.webp 400w,
/project/fix-it/img_hu4a47e7bb555165f3249c1881edac94ca_100119_f2bfcd2b8ef27eb87f80159d60305248.webp 760w,
/project/fix-it/img_hu4a47e7bb555165f3249c1881edac94ca_100119_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://manuelpagliuca.github.io/project/fix-it/img_hu4a47e7bb555165f3249c1881edac94ca_100119_b37034bddf09116b1976a55737d309a8.webp"
width="368"
height="613"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption data-pre="Figure&amp;nbsp;" data-post=":&amp;nbsp;" class="numbered">
How the flags are shown on the map.
&lt;/figcaption>&lt;/figure>
The complete title of the thesis is &lt;em>&amp;ldquo;Fix-it : Stream processing on event-driven system for
managing public disservices&amp;rdquo;&lt;/em>. The project itself consists of developing an &lt;strong>E.D.A.&lt;/strong> (Event-Driven Application)
system that will work with a mobile application called &amp;ldquo;&lt;strong>Fix-it&lt;/strong>&amp;rdquo;, which is developed using Android
Studio. The system is implemented with &lt;strong>Google Firebase&lt;/strong> and &lt;strong>Apache Kafka&lt;/strong> (stream processing).
Different technologies were involved in the implementation of this project, such as REST API, Stream Processing and
the Publisher-Subscribe pattern.&lt;/p>
&lt;p>The project was developed by just two people. We used the concepts of the Agile Manifesto to design our workflow, and everything was organized with a Kanban Board on Trello so that we could work consistently by breaking the work down into small parts.&lt;/p>
&lt;p>The whole thesis is available as a PDF
&lt;a href="https://manuelpagliuca.github.io/uploads/Manuel_Pagliuca_Tesi.pdf" target="_blank">here&lt;/a>
and was
written using LaTeX on Overleaf. The Abstract is downloadable
&lt;a href="https://manuelpagliuca.github.io/uploads/Abstract.pdf" target="_blank">here&lt;/a>
.
I gave a presentation of my thesis on Google Meet due to COVID-19, and I talked about my
work using these
&lt;a href="https://manuelpagliuca.github.io/uploads/Slides.pdf" target="_blank">slides&lt;/a>
. The project was realized under the
supervision of the Prof. &lt;a href="https://upobook.uniupo.it/davide.cerotti">Davide Cerotti&lt;/a>.&lt;/p></description></item><item><title>L-system in Unity</title><link>https://manuelpagliuca.github.io/project/l-system/</link><pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate><guid>https://manuelpagliuca.github.io/project/l-system/</guid><description>&lt;p>Artificial Intelligence for Videogames course, July 2022, M.Sc. in Computer Science @UniMi&lt;/p>
&lt;h2 id="about-the-project">About the project&lt;/h2>
&lt;p>This is a project for the course of A.I. for VideoGames at University of Milan, A.Y. 2021/2022. The aim of the project is to implement a Lindenmayer system for procedural generation of tree using discrete distributions (pseudo-random integers) for enhancing the believability of the project.&lt;/p>
&lt;center>&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/luaC1rPKbKg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>&lt;/center>
Check the YouTube video to see how the application works while listening to a synthetic explanation. If you want to look at the LateX report, just click
&lt;a href="https://manuelpagliuca.github.io/uploads/L_SYSTEM_AI4V_REPORT.pdf">this link&lt;/a>
. You are invited to send a pull request to the GitHub
&lt;a href="https://github.com/manuelpagliuca/l-system">repository&lt;/a>
.</description></item><item><title>Pain Recognition - Dataset analysis and experimental validation</title><link>https://manuelpagliuca.github.io/project/pain-recognition/</link><pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate><guid>https://manuelpagliuca.github.io/project/pain-recognition/</guid><description>&lt;p>Affective Computing and Natural Interaction courses, Jan 2023, M.Sc. in Computer Science @UniMi&lt;/p>
&lt;h2 id="about-the-project">About the project&lt;/h2>
&lt;p>This is a unified project for the courses Affective Computing and Natural Interaction at &lt;a href="https://phuselab.di.unimi.it/" target="_blank" rel="noopener">PhuseLab&lt;/a>, University of Milan, A.Y. 2021/2022.&lt;/p>
&lt;p>The aim of this project is to test the accuracy of early and late fusion approaches on a multi-modal dataset to classify the presence of pain in patients. Participants were subjected to an external heat pain stimulus using a physical device.&lt;/p>
&lt;p>Facial expressions and biophysical signals were recorded using cameras and electrodes, after which features were extracted. The descriptors from two different modalities were combined by testing both fusion approaches. Finally, classifications and accuracy estimates were made, based on which it was possible to determine that early fusion is the most accurate approach for the dataset considered.&lt;/p>
&lt;ul>
&lt;li>For more information about the project download the &lt;a href="https://manuelpagliuca.github.io/uploads/Pain_Detection_Manuel_Pagliuca_AC_NI_2022.pdf">report&lt;/a>.&lt;/li>
&lt;/ul>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/diagram.jpg" alt="Diagram" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Pain stimulation occurs in patients through electrostimulators applied to the wrists. During this experiment, different biophysical signals (GSR, EMG, &amp;hellip;) and facial expressions are recorded using a video camera.&lt;/p>
&lt;p>The analysis phase involves extracting features from the video signals using computer vision techniques. The features are Euclidean distances between specific facial landmarks and gradients in five regions of the face.&lt;/p>
&lt;p>Once the biophysical signals and video features are ready, fusion techniques are used for classification.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Early fusion&lt;/strong> involves combining signals and video features before classification, then training the classifier on the combined inputs.&lt;/li>
&lt;li>&lt;strong>Late fusion&lt;/strong> involves training three classifiers (of the same type) on different inputs (ECG, GSR, and video). For each sample in the testing set, the prediction is calculated with all three classifiers. The majority prediction is considered correct if it matches the &lt;em>ground truth&lt;/em>.&lt;/li>
&lt;/ul>
&lt;p>The classifier used in this project was &lt;em>Support Vector Machines&lt;/em>.&lt;/p>
&lt;h3 id="video-feature-extraction">Video feature extraction&lt;/h3>
&lt;h2 id="tools">Tools&lt;/h2>
&lt;ul>
&lt;li>IntelliJ IDEA and Python for developing the project application.&lt;/li>
&lt;li>Microsoft Excel for working with the &lt;code>.csv&lt;/code> files.&lt;/li>
&lt;li>&lt;a href="https://ieeexplore.ieee.org/document/6617456" target="_blank" rel="noopener">BioVid&lt;/a> dataset.&lt;/li>
&lt;/ul>
&lt;h2 id="dependencies">Dependencies&lt;/h2>
&lt;ul>
&lt;li>OpenCV&lt;/li>
&lt;li>MediaPipe&lt;/li>
&lt;li>Sk-learn&lt;/li>
&lt;li>Numpy&lt;/li>
&lt;/ul>
&lt;h2 id="computer-vision-techniques">Computer vision techniques&lt;/h2>
&lt;p>The computer vision techniques used were for the extraction of facial distances, gradients of facial folds, and head position.&lt;/p>
&lt;h3 id="facial-distances-and-head-pose-estimation">Facial distances and head pose estimation&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/facial_distances.gif" alt="Facial Distances" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="gradient-for-face-folds">Gradient for face folds&lt;/h3>
&lt;p>Gradients allow changes in regions of the face to be assessed. An arithmetic average of pixel values in these regions is calculated.
This average is then weighted by the number of frames in the video window (5 seconds in this dataset).&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/facial_gradients.gif" alt="Facial Gradients" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="switch-button">Switch button&lt;/h3>
&lt;p>A debug branch called &lt;code>cv-features&lt;/code> in this repository allows you to test computer vision systems directly with your computer&amp;rsquo;s camera. Using the tab key you can enable and disable debugging for gradients.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/switch.gif" alt="Switch" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h2 id="ideas-for-future-extensions">Ideas for future extensions&lt;/h2>
&lt;ul>
&lt;li>Calculate the gradient only when the pain stimulus is activated and not over the entire window.&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;/ul></description></item><item><title>SETA - SElf-driving TA-xi service</title><link>https://manuelpagliuca.github.io/project/seta/</link><pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate><guid>https://manuelpagliuca.github.io/project/seta/</guid><description>&lt;p>Distributed and Pervasive Systems courses, Jun 2022, M.Sc. in Computer Science @UniMi&lt;/p>
&lt;h2 id="about-the-project">About the project&lt;/h2>
&lt;p>Project for the course of &amp;ldquo;Distributed and Pervasive Systems&amp;rdquo; A.A. 2021/2022 for M.Sc.&amp;rsquo;s in Computer Science.&lt;/p>
&lt;p>The objective of the project is to design and develop SETA (Self-driving TAxi service), a
Self-driving &lt;em>peer-to-peer&lt;/em> taxi system for citizens of a smart city. The systems run on a centralized MQTT server which manages the taxis, they are able to communicate with each other via gRPC to ensure access to the resource.&lt;/p>
&lt;h2 id="dev-tools--languages">Dev Tools &amp;amp; Languages&lt;/h2>
&lt;h3 id="languages">Languages&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://www.oracle.com/java/technologies/javase/jdk18-archive-downloads.html" target="_blank" rel="noopener">Java SDK 18.0.2&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="technologies">Technologies&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://grpc.io/" target="_blank" rel="noopener">gRPC&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mqtt.org/" target="_blank" rel="noopener">MQTT&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Representational_state_transfer" target="_blank" rel="noopener">REST API&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.google.com/protocol-buffers" target="_blank" rel="noopener">Protocol Buffers&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="tools">Tools&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://www.jetbrains.com/idea/download/?section=mac" target="_blank" rel="noopener">IntelliJ IDEA&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/jgraph/drawio-desktop/releases" target="_blank" rel="noopener">draw.io&lt;/a> for drawing diagrams&lt;/li>
&lt;li>Git &amp;amp; GitHub as versioning system&lt;/li>
&lt;/ul>
&lt;p>Within this README are different conceptual diagrams that broadly define the general operation of the system, distributed algorithms, and synchronization procedures.&lt;/p>
&lt;p>These diagrams do not rigidly follow any model as they are simple and extensively commented.&lt;/p>
&lt;h3 id="guidelines">Guidelines&lt;/h3>
&lt;ul>
&lt;li>Rhombuses correspond to flow controls.&lt;/li>
&lt;li>Rectangles to of operations/procedures.&lt;/li>
&lt;li>Green circles are collection points.&lt;/li>
&lt;li>Rectangle colors stand for an object belonging to a certain class (so if there are multiple rectangles of the same color, they are multiple instances of the same class).&lt;/li>
&lt;li>White circles correspond to processes (used in diagrams for distributed algorithms).&lt;/li>
&lt;li>Gray circles correspond to threads (used in diagrams for synchronization).&lt;/li>
&lt;/ul>
&lt;h2 id="general-functioning-of-the-project">General functioning of the project&lt;/h2>
&lt;p>This is an outline of general operation of the system, it corresponds to what is required in the assignment delivery &lt;a href="Project_DPS_2022___SETA.pdf">document&lt;/a>.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/general_scheme.png" alt="General scheme" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h2 id="distributed-algorithms-diagrams">Distributed algorithms diagrams&lt;/h2>
&lt;h3 id="ricart--agrawala-algorithm-for-mutual-exclusion">Ricart &amp;amp; Agrawala algorithm for mutual exclusion&lt;/h3>
&lt;p>The algorithm was developed for guarantee the mutual exclusion to a critical section between multiple processes in a distributed system.&lt;/p>
&lt;p>The timestamps of the messages are sent in broadcast (in parallel) through the gRPC call &lt;code>coordinateRechargeStream()&lt;/code>. The logical clock synchronization is guaranteed through &lt;strong>Lamport&amp;rsquo;s algorithm&lt;/strong>.&lt;/p>
&lt;p>Consider the following diagram: the nodes in red want to access the critical section, while the other nodes are doing something else.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/ricart_agrawala_1.png" alt="Ricart &amp;amp;amp; Agrawala 1" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>In more depth, in the first phase (in which the requests are parallelized), the processes will build their lists of dependent nodes. These lists will contain all the nodes which got a smaller timestamp relative to theirs.&lt;/p>
&lt;p>A node will be able to enter a critical section (i.e., the recharging operation in this project) if it receives acknowledgments from all other nodes. If this doesn&amp;rsquo;t happen, it will have to wait for the remaining acknowledgments.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/ricart_agrawala_2.png" alt="Ricart &amp;amp;amp; Agrawala 2" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Once a node has finished the recharging operation, it sends an ACK message to the taxis in its list/queue. The first taxi to receive the required number of acknowledgments will access the critical section, and then the process repeats.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/ricart_agrawala_3.png" alt="Ricart &amp;amp;amp; Agrawala 3" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="ride-election-algorithm">Ride election algorithm&lt;/h3>
&lt;p>The SETA process generates two rides each 5 seconds on a random district, these two rides are posted on the respective topic of the district. Each taxi is subscribed only on the topic of the district in which it currently belongs.&lt;/p>
&lt;p>For simplicity, let&amp;rsquo;s assume only one ride (ride 5) is published by the SETA process on the first district. All processes subscribed to this topic (inside the green circle) will receive the message for ride 5.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/ride_election_1.png" alt="Ride Election 1" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>An election mechanism will start through the gRPC call &lt;code>coordinateRideStream()&lt;/code>. The request will be broadcast (including to taxis outside district 1) and executed in parallel. The request will contain the &lt;em>Euclidean distance to the starting point&lt;/em>, the &lt;em>battery levels&lt;/em> and the &lt;em>ID&lt;/em> of taxi which is sending the request.&lt;/p>
&lt;p>For simplicity, we are examining the evolution of the algorithm from the perspective of process 1.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/ride_election_2.png" alt="Ride Election 2" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Let&amp;rsquo;s also assume that process 1 has the smallest distance from the ride&amp;rsquo;s starting point. Essentially, this means that the taxis receiving the request will all answer with an ACK (meaning they have a worse distance, battery level, or greater ID than process 1). Only then will process 1 achieve consensus.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/ride_election_3.png" alt="Ride Election 3" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Now process 1 can execute ride 5. Before it passes to local execution of the ride, it publishes a message containing ride 5 on the &lt;code>seta/smartcity/completed&lt;/code> topic. This allows stopping the recycling of this message (we will see what this is below) and informs taxis which rides to ignore since they are already taken.&lt;/p>
&lt;p>This is because all taxis will have a local list containing all the completed rides from the topic, so they know which rides to avoid.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/ride_election_4.png" alt="Ride Election 4" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h4 id="ride-recycling">Ride recycling&lt;/h4>
&lt;p>A system enforces ride recycling. Each ride generated on the topics is embedded within the respective district queue. The queue priority is based on ride generation order (ride ID), so older rides are preferred.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/ride_recycling.png" alt="Ride Recycling" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h2 id="conceptual-schemes-of-synchronizations">Conceptual schemes of synchronizations&lt;/h2>
&lt;h3 id="user-input">User input&lt;/h3>
&lt;p>Command entry by users is handled by two threads. One thread for reading and executing the commands entered (&lt;strong>CLI&lt;/strong>, &lt;em>Command Line Interface&lt;/em>), and one thread for controlling the &lt;em>input stream&lt;/em> (&lt;strong>Input Checker&lt;/strong>).&lt;/p>
&lt;p>This approach is designed in such a way as to avoid &amp;ldquo;&lt;em>busy waiting&lt;/em>&amp;rdquo; phenomena. There is a shared &lt;em>dummy object&lt;/em> between the two objects; the thread for the CLI waits to receive an encoding on this object, notification will be sent by the Input Checker when the presence of user input is detected.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/busy_waiting.png" alt="Busy Waiting" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="recharge-operation">Recharge operation&lt;/h3>
&lt;p>A thread monitors cab battery levels (&lt;strong>Recharge Thread&lt;/strong>). To avoid &amp;ldquo;&lt;em>busy waiting&lt;/em>&amp;rdquo; phenomena, a &lt;em>dummy object&lt;/em> is shared between this thread and the &lt;strong>MQTT module&lt;/strong>.&lt;/p>
&lt;p>The recharge thread is initially waiting and will check the battery levels only after receiving the notification on the shared &lt;em>dummy object&lt;/em>.&lt;/p>
&lt;p>The MQTT module receives ride messages for its own district, and its callbacks can call methods (which function like threads). Upon completion of the function that handles the ride, we notify the &lt;em>dummy object&lt;/em> through &lt;code>notify()&lt;/code>.&lt;/p>
&lt;p>This way, a battery level check is made after a ride is finished. The charging procedure will only be started if the battery levels are below 30 percent.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/recharge_synchronization.png" alt="Synchronization of recharging spot" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="local-statistics">Local statistics&lt;/h3>
&lt;p>The collection and submission of local statistics involves different agents :&lt;/p>
&lt;ul>
&lt;li>A &lt;strong>PM10 simulator&lt;/strong> that generates random measurements of pollution levels at a random cadence.&lt;/li>
&lt;li>A &lt;strong>Pollution Buffer&lt;/strong> which is a data structure used for the collection and self-management (&lt;em>sliding window&lt;/em> technique) of measurements generated by the PM10 simulator.&lt;/li>
&lt;li>A thread for reading the PM10 measurements buffered in the Pollution Buffer, with addition of the other local statistics (&lt;em>total traveled km, battery levels, accomplished runs, &amp;hellip;&lt;/em>) and subsequent sending on the administrator server via POST request (&lt;strong>Local Stats Thread&lt;/strong>).&lt;/li>
&lt;li>A thread to ensure local statistics are sent every 15 seconds (&lt;strong>Enable Data Send Thread&lt;/strong>).&lt;/li>
&lt;/ul>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/localstats_synchronization.png" alt="Synchronization of local statistics" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>The Local Stats Thread reads the measurements, but its operation is governed by the Pollution Buffer&amp;rsquo;s internal data structure.&lt;/p>
&lt;p>Once the array of measurements is read, its average is calculated. Then a data structure is created that contains both this average and the other local statistics:&lt;/p>
&lt;ul>
&lt;li>Total traveled kilometers&lt;/li>
&lt;li>Battery levels&lt;/li>
&lt;li>Total accomplished runs&lt;/li>
&lt;/ul>
&lt;p>Every fifteen seconds, a POST request sends this data structure to the administrator server. To ensure this, a thread (Enable Data Thread) sets a boolean (initialized to false) to true.&lt;/p>
&lt;p>The Local Stats Thread checks this boolean. If it is true, the POST request is executed.&lt;/p>
&lt;p>Then the flag will be set to false again, and it will wait 15 seconds to be reactivated.&lt;/p>
&lt;h4 id="sliding-window">Sliding window&lt;/h4>
&lt;p>The Pollution Buffer presents a method that is constantly called at an unknown time by the PM10 simulator. The Pollution Buffer internal structure consists of a &lt;em>sliding window&lt;/em> of 50% of size 8 (each element is a PM10 measurements).&lt;/p>
&lt;p>Once the internal data structure reaches maximum capacity, the Local Stats Thread will read it. The read operation involves a left shift of 50% of the elements (&lt;em>i.e.,&lt;/em> 4 elements), after which the elements added by the PM10 simulator will be allocated starting from the fifth.
When the eighth element is added again, a new reading of the sliding window can be performed.&lt;/p>
&lt;p>In this way, the various sliding windows that are read will share four elements. That is, the sliding window of iteration &lt;code>t-1&lt;/code> will have the same last four elements as the first four elements of the sliding window at time &lt;code>t&lt;/code>.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/sliding_window.png" alt="Sliding Window" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>Subdivision of surfaces</title><link>https://manuelpagliuca.github.io/project/geometry/</link><pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate><guid>https://manuelpagliuca.github.io/project/geometry/</guid><description>&lt;p>Computational Geometry Course, March 2021, M.Sc. in Computer Science @UniMi&lt;/p>
&lt;h2 id="about-the-project">About the project&lt;/h2>
&lt;figure id="figure-icosahedron-obtained-with-the-application">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Icosahedron obtained with the application." srcset="
/project/geometry/img_hu92825ff421db5b452c03fb61016d2789_175632_61a89ba5ff0edc125b01e8b25e2f98da.webp 400w,
/project/geometry/img_hu92825ff421db5b452c03fb61016d2789_175632_5e4e12b5ba32a7e3a372e59919161a64.webp 760w,
/project/geometry/img_hu92825ff421db5b452c03fb61016d2789_175632_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://manuelpagliuca.github.io/project/geometry/img_hu92825ff421db5b452c03fb61016d2789_175632_61a89ba5ff0edc125b01e8b25e2f98da.webp"
width="760"
height="681"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption data-pre="Figure&amp;nbsp;" data-post=":&amp;nbsp;" class="numbered">
Icosahedron obtained with the application.
&lt;/figcaption>&lt;/figure>
&lt;p>The aims of this project were to study how tessellation works with simple domains and to
implement the basic logic for triangulating the vertices of simple
objects like cubes and then more complex ones like tori, spheres, and cylinders.&lt;/p>
&lt;center>&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/tK8yzO6Btho"
title="YouTube video player" frameborder="0"
allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
allowfullscreen>&lt;/iframe>&lt;/center>
For the course project, a report was also produced in the form of a &lt;a
href="http://www.mat.unimi.it/users/alzati/Geometria_Computazionale_98-99/apps/trietas/index.html">website&lt;/a>
(fully in &lt;i>Italian&lt;/i>), hosted by the university's mathematics department &lt;i>Federigo Enriques&lt;/i>. It contains
the theory behind the software, the techniques involved, a user manual for the application, and many example videos.
&lt;p>It is possible to download the source code of the project from the &lt;a
href="https://github.com/manuelpagliuca/Computational_Geometry_2021">GitHub Repository&lt;/a> by
following this link. The course was a complete math course and the project was developed using the
&lt;strong>OpenGL&lt;/strong> specification.&lt;/p>
&lt;p>By accessing the &lt;a
href="http://www.mat.unimi.it/users/alzati/Geometria_Computazionale_98-99/corso/autori.html">authors
section&lt;/a> of the course website, you can read a note from the course teacher under my name: &lt;br>&lt;br>&lt;/p>
&lt;p>&lt;em>&amp;ldquo;has developed the project related to the triangulation and tessellation of the lateral
surface of some geometric solids obtaining truly amazing visual effects.&amp;rdquo;&lt;/em> - Prof. Alzati&lt;/p></description></item></channel></rss>