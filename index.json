[{"authors":null,"categories":null,"content":"Hello! üëãüèª I am Manuel, a 27-year-old computer scientist who recently completed my Master‚Äôs degree üéì (09/10/2023). I chose to pursue a master‚Äôs degree to broaden my horizons in the field of Computer Science, while gaining valuable practical experience through internships in the working world.\nI am currently working on tidying up some things in my life; I do not yet have an occupation.\nI‚Äôve always had a deep passion for computer programming and the world related to it. I‚Äôve developed a strong interest in many fields, in particular:\nAlgorithms \u0026amp; Data Structures Distributed Systems Computer Graphics Artificial Intelligence Computer Vision For this reason, I am a passionate programmer, in that what I love to do most is to design solutions that effectively address problems and then improve their performance. I have worked with several programming languages and see them as tools to help the programmer implement the actual solution, I do not see them as the end goal.\nThis corner of the internet is dedicated to a portfolio showcasing my academic and professional journey. However, it‚Äôs important to emphasize that this space is not solely about serving as a portfolio. It‚Äôs also a place where I share personal projects, images, posts, and resources.\nIn my leisure time, I take pleasure in activities such as running, weightlifting, reading, and playing the guitar. As passions tend to evolve with time, who knows what the future has in store for me? üåå\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Hello! üëãüèª I am Manuel, a 27-year-old computer scientist who recently completed my Master‚Äôs degree üéì (09/10/2023). I chose to pursue a master‚Äôs degree to broaden my horizons in the field of Computer Science, while gaining valuable practical experience through internships in the working world.","tags":null,"title":"Manuel Pagliuca","type":"authors"},{"authors":null,"categories":null,"content":"Master‚Äôs Thesis, October 2023, M.Sc. in Computer Science @UniMI\nAbstract This thesis aims to empirically investigate the imaginable performance for data structures suitable for effectively representing extreme-resolution 3D polygonal surfaces designed for multi-resolution rendering on GPUs.\nTo this end, supporting algorithms will be designed, implemented, and tested that transform ‚Äútraditional‚Äù (i.e., indexed) high-resolution triangular meshes into the analyzed data structures, and then measure the approximation errors introduced through appropriate geometric measurements.\nOther alternative schemes will be studied, which are considered variants of the so-called ‚Äúmicro-meshes‚Äù scheme offered by the latest generation of vendor-specific GPU hardware. These data structures are characterized by the use of a semi-regular subdivision of a medium-resolution ‚Äúbase mesh,‚Äù followed by displacement of the generated vertices. Variants introduced may include the adoption of an anisotropic subdivision step, the adoption of an irregular recursive subdivision scheme, or others.\nDependencies Qt OpenGL Mathematics The headers are placed in the directory Dependencies\\GLM PyMeshLab Sample models As sample models in this repository, I‚Äôve prepared different versions of Pallas Cat by printable_models\nPython script (empirical analysis) Executing this script will generate n samples for both subdivision schemes (current and variant). A table (as a text file) containing the face quality values (according to the inradius/circumradius metric) will be built for both batches of samples.\nThe table will be ordered by a factor F used, this will allow the comparison of one sample of a table with a sample of the other table, the factor modulates the intensity of subdivisions.\nIn the thesis, the comparison is also described using the face area coefficent of variation\nThe commands generate two batches of samples, and multiple executions of the commands are used for the analysis since multiple models are tested.\npython face-stats.py --base-mesh=base.obj --target-mesh=target.obj Default values if you omit some of the options:\n--base-mesh = pallas_124.obj --target-mesh = pallas_5000.obj Graphical User Interface Sample loading Scheme subdivisions Displacement CLI commands Generate a single subdivided sample Exports the given base mesh‚Äôs subdivided (not displaced) mesh.\nanisotropic-micromesh.exe --base-mesh=base.obj --microfaces=100 In this example the base mesh is being subdivided by the amount of micro-faces passed (F can‚Äôt be passed, since it works in function of the target mesh) using the current scheme (‚Äúisotropic‚Äù scheme).\nGenerate sample Exports the subdivided and displaced mesh given the inputs\nanisotropic_micromesh.exe gen-sample --base-mesh=base.obj --target=target.obj --scheme=aniso --factor=3.5 In this example the base mesh will be subdivided using the anisotropic subdivision scheme, with a factor F=3.5 (subdividing x3.5 times the faces of the target mesh).\n","date":1698226920,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1698226920,"objectID":"4daee3b09ef23685dbf664ff02a319a9","permalink":"https://manuelpagliuca.github.io/project/anisotropic-mm/","publishdate":"2023-10-25T09:42:00Z","relpermalink":"/project/anisotropic-mm/","section":"project","summary":"My Master's Thesis argument","tags":["Computer Graphics","Math","Geometry Processing"],"title":"Efficient representations of high‚Äëresolution polygonal surfaces, adding anisotropy control to the Micro‚ÄëMesh schema","type":"project"},{"authors":null,"categories":null,"content":"GPU Computing Course, July 2021, M.Sc. in Computer Science @UniMi\nAbout the project During the course of GPU Computing I decided to implement my old version of the Ray Tracer (based on the Ray Tracing in One Weekend from Peter Shirley ) on CUDA. In this paper I compared the two Ray Tracers underlining the huge differences in rendering speed (even without achieving the best warp efficiency).\nFor the comparison I used the same scene in both the implementation composed by 8 different spheres with different materials between lambertian, metal and dielectrics. I highly recommend to check the comparisons and metrics at the end of the paper, the GitHub repository is at this link if you want to see some render just download this zip.\n","date":1624752e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624752e3,"objectID":"4295a7c9a50f9e96ed156924e02782f8","permalink":"https://manuelpagliuca.github.io/project/rt/","publishdate":"2021-06-27T00:00:00Z","relpermalink":"/project/rt/","section":"project","summary":"Implementation, Comparison and Profiling of GPU and CPU implementation of the same Ray Tracer.","tags":["GP-GPU","Computer Graphics"],"title":"CUDA Ray Tracer","type":"project"},{"authors":null,"categories":null,"content":"Real-Time Graphics Programming Course, July 2021, M.Sc. in Computer Science @UniMi\nAbout the project This was a project I made for the course of Real-time Graphics Programming. The course provided extensive knowledge about real-time computer graphics (you can check the notes I took). At the end of the course, in addition to an oral exam, there was a project related to graphic programming to be developed with OpenGL. I asked Prof. Gadia if there was the possibility of developing it with Vulkan, he granted me the possibility to take this extra-step, it was very tiring but fruitful from the point of view of learning.\nThe project consists in a deferred renderer to improve the overall efficiency of the application in the usage of lights. The scene is composed of three models of the same character, a floor and twenty lights (whose movement and color can be modified), there is the notes containing the various metrics obtained using a different number of lights. The GitHub repository is accessible at this link.\n","date":1624752e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624752e3,"objectID":"244f4c2e94cbbd7b9c9c5fb3a03c1c23","permalink":"https://manuelpagliuca.github.io/project/render/","publishdate":"2021-06-27T00:00:00Z","relpermalink":"/project/render/","section":"project","summary":"Implementation of deferred rendering technique in Vulkan","tags":["Computer Graphics","Misc"],"title":"Deferred renderer","type":"project"},{"authors":null,"categories":null,"content":"Bachelor‚Äôs Thesis, December 2019, B.Sc. in Computer Science @UniUPO\nAbout the thesis How the flags are shown on the map. The complete title of the thesis is ‚ÄúFix-it : Stream processing on event-driven system for managing public disservices‚Äù. The project itself consist in developing an E.D.A. (Event-Driven Application) system that will work on a mobile application called ‚ÄúFix-it‚Äù, which is developed using Android Studio. The system is implemented with Google Firebase and Apache Kafka (stream processing). Different technologies involved in the implementation of this project like REST API, Stream Processing and Publisher-Subscribe pattern.\nThe project was developed only by just two guys, we used the concepts of the Agile Manifesto to design our workflow, everything was organized with a Kanban Board on Trello so that we could work consistently by breaking the work down into small parts.\nThe whole thesis is downloadable as PDF here , was written using LaTeX on Overleaf, the Abstract is downloadable here . I attained a presentation of my thesis on Google Meet due to COVID-19, and I talked about my work using these slides . The project was realized under the supervision of the Prof. Davide Cerotti.\n","date":1624752e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624752e3,"objectID":"9820567e36a8af97931d8afa3730a3b2","permalink":"https://manuelpagliuca.github.io/project/fix-it/","publishdate":"2021-06-27T00:00:00Z","relpermalink":"/project/fix-it/","section":"project","summary":"My Bachelor's Thesis argument","tags":["Distributed Systems","Misc"],"title":"Fix-It, Stream processing on event-driven system for managing public disservices","type":"project"},{"authors":null,"categories":null,"content":"Artificial Intelligence for Videogames course, July 2022, M.Sc. in Computer Science @UniMi\nAbout the project This is a project for the course of A.I. for VideoGames at University of Milan, A.Y. 2021/2022. The aim of the project is to implement a Lindenmayer system for procedural generation of tree using discrete distributions (pseudo-random integers) for enhancing the believability of the project.\nCheck the YouTube video for check how the application works while listening to a synthetic explanation. If you want to look at the LateX report, just click this link . You are invited to send a pull request to the GitHub repository . ","date":1624752e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624752e3,"objectID":"0e63d1286d8bd0eff18d66578fb6fcd7","permalink":"https://manuelpagliuca.github.io/project/l-system/","publishdate":"2021-06-27T00:00:00Z","relpermalink":"/project/l-system/","section":"project","summary":"Implementation of a Lindenmayer system for the generation of trees through Unity in C#.","tags":["Computer Graphics","Math","Misc"],"title":"L-system in Unity","type":"project"},{"authors":null,"categories":null,"content":"Affective Computing and Natural Interaction courses, Jan 2023, M.Sc. in Computer Science @UniMi\nAbout the project This is a unified project for the courses Affective Computing and Natural Interaction at PhuseLab, University of Milan, A.Y. 2021/2022.\nThe aim of this project is to test the accuracy of early and late fusion approaches on a multi-modal dataset to classify the presence of pain in patients. Participants were subjected to an external heat-pain stimulus through a physical device.\nTheir facial expressions and biophysical signals were recorded using cameras and the application of electrodes, then features were extracted. The descriptors came from two different modalities and will be combined by testing both fusion approaches. Finally, classifications and accuracy estimates were made, based on which it was possible to determine that early fusion is the most accurate approach for the dataset considered.\nFor more information about the project download the report. Pain stimulation occurs in patients through electrostimulators applied to the wrists. When this experiment is performed different bio-potential signals (GSR, EMG, ‚Ä¶) and facial expressions are recorded through (through a video camera).\nThe analysis phase involves extracting features from the video signals through computer vision techniques. The features involved are Euclidean distances on particular facial landmarks and gradients on 5 regions of the face.\nOnce the biopotential signals and video features are ready, fusion techniques are used to perform classification.\nEarly fusion involves fusing signals and video features a priori concerning classification. Then train the classifier on the combined inputs. Late fusion involves training three classifiers (of the same type) on different inputs (ECG, GSR, and video), then for each sample in the testing set its prediction is calculated with all three classifiers. The majority prediction is considered; if that prediction coincides with the ground truth, then that prediction is considered correct. The classifier used in this project was Support Vector Machines.\nVideo feature extraction Tools IntelliJ IDEA and Python for developing the project application. Microsoft Excel for working with the .csv files. BioVid dataset. Dependencies OpenCV MediaPipe Sk-learn Numpy Computer vision techniques The computer vision techniques used were for the extraction of facial distances, gradients of facial folds, and head position.\nFacial distances and head pose estimation Gradient for face folds Gradients allow changes in regions of the face to be assessed. An arithmetic average of pixel values in these regions is calculated. This average is again weighted by the number of frames in the video window(which in the dataset was 5 seconds).\nSwitch button There is a debug branch called cv-features in this repository where you can try computer vision systems directly with your computer camera. Using the tab key you can enable and disable debugging for gradients.\nIdeas for future extensions Calculate the gradient only when the pain stimulus is activated and not over the entire window. ‚Ä¶ ","date":1624752e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624752e3,"objectID":"21652ec8d7d8715d90ea4beaae64d756","permalink":"https://manuelpagliuca.github.io/project/pain-recognition/","publishdate":"2021-06-27T00:00:00Z","relpermalink":"/project/pain-recognition/","section":"project","summary":"Test the accuracy of early and late fusion approaches on a multi-modal dataset to classify the presence of pain in patients.","tags":["Computer Vision","AI","Misc"],"title":"Pain Recognition - Dataset analysis and experimental validation","type":"project"},{"authors":null,"categories":null,"content":"Distributed and Pervasive Systems courses, Jun 2022, M.Sc. in Computer Science @UniMi\nAbout the project Project for the course of ‚ÄúDistributed and Pervasive Systems‚Äù A.A. 2021/2022 for M.Sc.‚Äôs in Computer Science.\nThe objective of the project is to design and develop SETA (Self-driving TAxi service), a Self-driving peer-to-peer taxi system for citizens of a smart city. The systems run on a centralized MQTT server which manages the taxis, they are able to communicate with each other via gRPC to ensure access to the resource.\nDev Tools \u0026amp; Languages Languages Java SDK 18.0.2 Technologies gRPC MQTT REST API Protocol Buffers Tools IntelliJ IDEA draw.io for drawing diagrams Git \u0026amp; GitHub as versioning system Within this README are different conceptual diagrams that broadly define the general operation of the system, distributed algorithms, and synchronization procedures.\nThese diagrams do not rigidly follow any model as they are simple and extensively commented.\nGuidelines Rhombuses correspond to flow controls. Rectangles to of operations/procedures. Green circles are collection points. Rectangle colors stand for an object belonging to a certain class (so if there are multiple rectangles of the same color, they are multiple instances of the same class). White circles correspond to processes (used in diagrams for distributed algorithms). Gray circles correspond to threads (used in diagrams for synchronization). General functioning of the project This is an outline of general operation of the system, it corresponds to what is required in the assignment delivery document.\nDistributed algorithms diagrams Ricart \u0026amp; Agrawala algorithm for mutual exclusion The algorithm was developed for guarantee the mutual exclusion to a critical section between multiple processes in a distributed system.\nThe timestamps of the messages are sent in broadcast (in parallel) through the gRPC call coordinateRechargeStream(). The logical clock synchronization is guaranteed through Lamport‚Äôs algorithm.\nLet‚Äôs consider the following diagram, the nodes in red want to access to the critical section, while the other nodes are doing anything else.\nMore in depth in the first phase (in which the requests are parallelized) the processes will build their lists of dependent nodes. These lists will contain all the nodes which got a smaller timestamp relative to their.\nA node will be able to enter a critical section (i.e., in this project is the recharging operation) if it receives the ACKs from all the other nodes. If this doesn‚Äôt happens it will have to wait the residual ACKs.\nOnce that a node has finished with the recharging operation, it will sends an ACK message to the taxi of his list/queue. The first taxis who will fill the number of attended ACKs will access the critical section, and then story repeats.\nRide election algorithm The SETA process generates two rides each 5 seconds on a random district, these two rides are posted on the respective topic of the district. Each taxi is subscribed only on the topic of the district in which it currently belongs.\nFor simplicity let‚Äôs assume only one ride (the ride 5) to be published from the SETA process on the first district. All the processes which are subscribed to this topic (inside the green circle) will receive the message for the ride 5.\nAn election mechanism will start through the gRPC call coordinateRideStream(), the request will be performed in broadcast (also to taxi out from district 1) and they will be executed in parallel. The request will contain the Euclidean distance to the starting point, the battery levels and the ID of taxi which is sending the request.\nFor sake of simplicity we are seeing the evolution of the algorithm only from the point of view of the process 1.\nLet‚Äôs also assume that the process 1 is the process with the smallest distance from the starting point of the ride. Essentially, this means that the taxi who receives the request will all answer with an ACK (this means that they got a worst distance, battery or grater ID respect to process 1), only in this case the process 1 will achieve the consensus.\nNow the process 1 can execute the ride 5, before it even pass to the local execution of the ride, it publish a message containing the ride 5 on the seta/smartcity/completed topic. This will allow to stop recycling this message (we will see what is it below) and also making know to the taxi which ride ignore since it is already taken.\nThis because all the taxi will have a local list containing all the completed rides taken from the topic, in this way they know which ride to avoid.\nRide recycling There is a system that enforces the recycling of runs, each run that is generated on the topics is embedded within the relative queue of the district. The priority of the queues is based on the order (run ID) of run generation, so older runs will be preferred.\nConceptual schemes of synchronizations User input Command entry by users is handled by two threads. One thread for reading and ‚Ä¶","date":1624752e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624752e3,"objectID":"c1a85b272412065daaa52e9fa8ee0ca4","permalink":"https://manuelpagliuca.github.io/project/seta/","publishdate":"2021-06-27T00:00:00Z","relpermalink":"/project/seta/","section":"project","summary":"Test the accuracy of early and late fusion approaches on a multi-modal dataset to classify the presence of pain in patients.","tags":["Distributed Systems","Misc"],"title":"SETA - SElf-driving TA-xi service","type":"project"},{"authors":null,"categories":null,"content":"Computational Geometry Course, March 2021, M.Sc. in Computer Science @UniMi\nAbout the project Icosahedron obtained with the application. The aims of this project was to study how the tessellation works with simple domains and to implement the basic logic for triangulate the vertices of simple objects like cubes and then with more complex like torus, sphere and cylinder.\nFor the course project there was also a need to produce a report in the form of website (fully in italian) which is hosted from the university\u0026#39;s mathematics department Federigo Enriques. It contains the theory behind the software, the technique involved, user manual of the application and lot of example videos about the application. Is possible to download the source code of the project from the GitHub Repository by following this link. The course was a complete math course and the project was developed using the OpenGL specification.\nBy accessing the authors section of the course website, is possible to read under my name a note from the course teacher saying: ‚Äúhas developed the project related to the triangulation and tessellation of the lateral surface of some geometric solids obtaining truly amazing visual effects.‚Äù - Prof. Alzati\n","date":1624752e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624752e3,"objectID":"12519c8edd74f86a00c8822035310e0e","permalink":"https://manuelpagliuca.github.io/project/geometry/","publishdate":"2021-06-27T00:00:00Z","relpermalink":"/project/geometry/","section":"project","summary":"Study and implementation of computational geometry techniques with OpenGL.","tags":["Computer Graphics","Math"],"title":"Subdivision of surfaces","type":"project"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let‚Äôs make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://manuelpagliuca.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"}]