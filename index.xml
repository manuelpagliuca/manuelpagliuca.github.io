<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Manuel Pagliuca</title><link>https://manuelpagliuca.github.io/</link><atom:link href="https://manuelpagliuca.github.io/index.xml" rel="self" type="application/rss+xml"/><description>Manuel Pagliuca</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 24 Oct 2022 00:00:00 +0000</lastBuildDate><image><url>https://manuelpagliuca.github.io/media/icon_hu4a5b1b591c5ae08b60d2e1d27385e465_426_512x512_fill_lanczos_center_3.png</url><title>Manuel Pagliuca</title><link>https://manuelpagliuca.github.io/</link></image><item><title>Efficient representations of high‑resolution polygonal surfaces, adding anisotropy control to the Micro‑Mesh schema</title><link>https://manuelpagliuca.github.io/project/anisotropic-mm/</link><pubDate>Wed, 25 Oct 2023 09:42:00 +0000</pubDate><guid>https://manuelpagliuca.github.io/project/anisotropic-mm/</guid><description>&lt;p>Master&amp;rsquo;s Thesis, October 2023, M.Sc. in Computer Science @UniMI&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="" srcset="
/project/anisotropic-mm/dragon_render_huf8cfb674e3e9d5aaba137dd8763e6e91_6565607_6a9b7e8c34208890c54153e224093422.webp 400w,
/project/anisotropic-mm/dragon_render_huf8cfb674e3e9d5aaba137dd8763e6e91_6565607_be20a4681937039f09773afed417acd7.webp 760w,
/project/anisotropic-mm/dragon_render_huf8cfb674e3e9d5aaba137dd8763e6e91_6565607_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://manuelpagliuca.github.io/project/anisotropic-mm/dragon_render_huf8cfb674e3e9d5aaba137dd8763e6e91_6565607_6a9b7e8c34208890c54153e224093422.webp"
width="760"
height="530"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="abstractuploadsabstract_master_s_thesis__en_pdf">&lt;a href="https://manuelpagliuca.github.io/uploads/Abstract_Master_s_Thesis__en_.pdf">Abstract&lt;/a>&lt;/h3>
&lt;p>This &lt;a href="https://manuelpagliuca.github.io/uploads/MANUEL_PAGLIUCA_ANISOTROPIC_MM_Master_s_Thesis__Integral_.pdf">thesis&lt;/a> aims to empirically investigate the imaginable performance for data structures suitable for effectively representing extreme-resolution 3D polygonal surfaces designed for multi-resolution rendering on GPUs.&lt;/p>
&lt;p>To this end, supporting algorithms will be designed, implemented, and tested that transform &amp;ldquo;traditional&amp;rdquo; (i.e., indexed) high-resolution triangular meshes into the analyzed data structures, and then measure the approximation errors introduced through appropriate geometric measurements.&lt;/p>
&lt;p>Other alternative schemes will be studied, which are considered variants of the so-called &amp;ldquo;micro-meshes&amp;rdquo; scheme offered by the latest generation of vendor-specific GPU hardware. These data structures are characterized by the use of a semi-regular subdivision of a medium-resolution &amp;ldquo;base mesh,&amp;rdquo; followed by displacement of the generated vertices. Variants introduced may include the adoption of an anisotropic subdivision step, the adoption of an irregular recursive subdivision scheme, or others.&lt;/p>
&lt;h2 id="dependencies">Dependencies&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.qt.io/" target="_blank" rel="noopener">Qt&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://glm.g-truc.net/0.9.9/index.html" target="_blank" rel="noopener">OpenGL Mathematics&lt;/a>
&lt;ul>
&lt;li>The headers are placed in the directory &lt;code>Dependencies\GLM&lt;/code>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="https://pymeshlab.readthedocs.io/en/latest/installation.html" target="_blank" rel="noopener">PyMeshLab&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="sample-models">Sample models&lt;/h2>
&lt;p>As sample models in this repository, I&amp;rsquo;ve prepared different versions of &lt;a href="https://free3d.com/3d-model/pallas-cat-v1--576987.html" target="_blank" rel="noopener">Pallas Cat&lt;/a> by &lt;em>printable_models&lt;/em>&lt;/p>
&lt;h2 id="python-script-empirical-analysis">Python script (empirical analysis)&lt;/h2>
&lt;p>Executing this script will generate &lt;strong>n&lt;/strong> samples for both subdivision schemes (current and variant). A table (as a text file) containing the face quality values (according to the inradius/circumradius metric) will be built for both batches of samples.&lt;/p>
&lt;p>The table will be ordered by a factor &lt;strong>F&lt;/strong> used, this will allow the comparison of one sample of a table with a sample of the other table, the factor modulates the intensity of subdivisions.&lt;/p>
&lt;p>In the &lt;a href="https://manuelpagliuca.github.io/uploads/MANUEL_PAGLIUCA_ANISOTROPIC_MM_Master_s_Thesis__Integral_.pdf" target="_blank" rel="noopener">thesis&lt;/a>, the comparison is also described using the face area coefficent of variation&lt;/p>
&lt;p>The commands generate two batches of samples, and multiple executions of the commands are used for the analysis since multiple models are tested.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-batch" data-lang="batch">&lt;span class="line">&lt;span class="cl">python face-stats.py --base-mesh=base.obj --target-mesh=target.obj
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Default values if you &lt;em>omit&lt;/em> some of the options:&lt;/p>
&lt;ul>
&lt;li>&lt;code>--base-mesh = pallas_124.obj&lt;/code>&lt;/li>
&lt;li>&lt;code>--target-mesh = pallas_5000.obj&lt;/code>&lt;/li>
&lt;/ul>
&lt;h2 id="graphical-user-interface">Graphical User Interface&lt;/h2>
&lt;h3 id="sample-loading">Sample loading&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt=""
src="https://manuelpagliuca.github.io/project/anisotropic-mm/sample_loading.gif"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="scheme-subdivisions">Scheme subdivisions&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt=""
src="https://manuelpagliuca.github.io/project/anisotropic-mm/subdivisions.gif"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h4 id="displacement">Displacement&lt;/h4>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt=""
src="https://manuelpagliuca.github.io/project/anisotropic-mm/displacement.gif"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="cli-commands">CLI commands&lt;/h3>
&lt;h4 id="generate-a-single-subdivided-sample">Generate a single subdivided sample&lt;/h4>
&lt;p>&lt;strong>Exports&lt;/strong> the given base mesh&amp;rsquo;s subdivided (not displaced) mesh.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-cmd" data-lang="cmd">&lt;span class="line">&lt;span class="cl">anisotropic-micromesh.exe --base-mesh=base.obj --microfaces=100
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>In this example the base mesh is being subdivided by the amount of micro-faces passed (&lt;code>F&lt;/code> can&amp;rsquo;t be passed, since it works in function of the target mesh) using the current scheme (&amp;ldquo;isotropic&amp;rdquo; scheme).&lt;/p>
&lt;/blockquote>
&lt;h4 id="generate-sample">Generate sample&lt;/h4>
&lt;p>&lt;strong>Exports&lt;/strong> the subdivided and displaced mesh given the inputs&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-cmd" data-lang="cmd">&lt;span class="line">&lt;span class="cl">anisotropic_micromesh.exe gen-sample --base-mesh=base.obj --target=target.obj --scheme=aniso --factor=3.5
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>In this example the base mesh will be subdivided using the &lt;code>anisotropic&lt;/code> subdivision scheme, with a factor &lt;code>F=3.5&lt;/code> (subdividing x3.5 times the faces of the target mesh).&lt;/p>
&lt;/blockquote></description></item><item><title>Why you should learn geography?</title><link>https://manuelpagliuca.github.io/post/should-learn-geography/</link><pubDate>Wed, 12 Oct 2022 00:00:00 +0000</pubDate><guid>https://manuelpagliuca.github.io/post/should-learn-geography/</guid><description>
&lt;figure id="figure-world-map">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="World map." srcset="
/post/should-learn-geography/world-map-1_huf15f3ba890c6c230d521f9341324f525_111111_d3bedc22cbf2a72af0a029d556088cce.webp 400w,
/post/should-learn-geography/world-map-1_huf15f3ba890c6c230d521f9341324f525_111111_f1422d01dac09103174033b9bf42e53b.webp 760w,
/post/should-learn-geography/world-map-1_huf15f3ba890c6c230d521f9341324f525_111111_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://manuelpagliuca.github.io/post/should-learn-geography/world-map-1_huf15f3ba890c6c230d521f9341324f525_111111_d3bedc22cbf2a72af0a029d556088cce.webp"
width="760"
height="562"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption data-pre="Figure&amp;nbsp;" data-post=":&amp;nbsp;" class="numbered">
World map.
&lt;/figcaption>&lt;/figure>
&lt;p>Maps are surely a fascinating tool for geographers and curious people, but they are just a little part of Geography.&lt;/p>
&lt;p>First of all, Geography is a science, it is the study of the earth’s surface (in all its various aspects of it, e.g. &lt;em>extension, distribution, biological, social,&lt;/em> …) and the relationship between people and their environments.&lt;/p>
&lt;p>As we can state, Geography is much bigger than Cartography and Topography, since it adds the investigation of dynamics and causes of the position of the Earth in space caused by phenomena and based on its characteristics.&lt;/p>
&lt;p>From Wikipedia :&lt;/p>
&lt;p>&lt;strong>Cartography&lt;/strong> is the set of scientific, technical, and artistic knowledge aimed at the representation, symbolic, but truthful, on flat (geographical maps) or spherical (globes) supports, of geographical, statistical, demographic, economic, political, cultural, relative to the geographic space represented.
&lt;strong>Topography&lt;/strong> is the science that has as its purpose the determination and metric representation through drawing a map with conventional signs of the Earth’s surface.
There are several branches of Geography, by the way, this intro was just for making clear that learning &lt;strong>country maps it’s different from learning Geography&lt;/strong>.&lt;/p>
&lt;p>If you are interested in learning more about Geography you should consider these resources :&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://www.youtube.com/watch?v=Di5vJwH0VZ8&amp;amp;feature=youtu.be" target="_blank" rel="noopener">Crash Course Geography&lt;/a> from &lt;em>CrashCourse&lt;/em> on YouTube, seems the best way to start, I can’t wait for watching it.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Other must lectures are “&lt;a href="https://en.wikipedia.org/wiki/Prisoners_of_Geography" target="_blank" rel="noopener">&lt;em>Prisoners of Geography: Ten Maps That Explain Everything About the World (Politics of Place)&lt;/em>&lt;/a>“, and “&lt;a href="https://en.wikipedia.org/wiki/The_Power_of_Geography" target="_blank" rel="noopener">&lt;em>The Power of Geography: Ten Maps That Reveal the Future of Our World&lt;/em>&lt;/a>” both by &lt;a href="https://en.wikipedia.org/wiki/Tim_Marshall_%28journalist%29" target="_blank" rel="noopener">Tim Marshall&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>“&lt;a href="https://www.amazon.it/Geografia-umana-approccio-visuale-Greiner/dp/8860085683" target="_blank" rel="noopener">&lt;em>Geografia umana. Un approccio visuale&lt;/em>&lt;/a>“, by Alyson L. Greiner, Giuseppe Dematteis and Carla Lanza. I found only the italian version of this book (I still have to read this).&lt;/p>
&lt;ul>
&lt;li>As an alternative, this seems similar to “Human Geography A Spatial Perspective AP Edition” by Sarah Bednarz, Mark Bockenhauer, and Fredrik Hiebert.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h1 id="why-should-we-learn-the-world-map">Why should we learn the world map?&lt;/h1>
&lt;p>From elementary school to middle school Geography is taught in general terms about the seas and the &lt;em>land&lt;/em>. But after this time in school, this wonderful subject isn’t taught anymore, leaving it in the most incomplete manner possible.&lt;/p>
&lt;p>My personal experience was that at the end of these classes I still had no idea how countries were positioned in the world.&lt;/p>
&lt;p>Geography is not considered as important as &lt;em>Math, English, History&lt;/em>, and other core subjects, by the way, is a tool that gives you an important enrichment to a well-rounded education.&lt;/p>
&lt;p>A list of things we still don’t know about the normal scholastic system:&lt;/p>
&lt;ul>
&lt;li>The spatial position of world countries&lt;/li>
&lt;li>The spatial position of seas&lt;/li>
&lt;li>World capitals&lt;/li>
&lt;li>The flags of the countries&lt;/li>
&lt;li>The current wars&lt;/li>
&lt;/ul>
&lt;p>Exactly, wars, and modern Geography if studied from the correct resources (which will be given on this page) can tell you a lot about the current global situation of the world, this will result in a knowledge boost if you are willing to study &lt;em>History&lt;/em> (and you probably should).&lt;/p>
&lt;h1 id="why-you-should-study-geography">Why you should study geography?&lt;/h1>
&lt;p>You could study the world map just to impress people, but this isn’t the main superpower that is given by Geography, there are many others. If you know better Geography you can understand better Politics, History, and also human behavior.&lt;/p>
&lt;p>There are many types of Geography, one is also called mathematical geography, it’s okay we won’t go into that 😋; we are interested in &lt;strong>physical geography&lt;/strong>, which is the study of the physical characteristics of the land like climate, water distribution, and natural resources.&lt;/p>
&lt;p>If you want to have a better economical and political idea, you should study physical geography for mainly two things&lt;/p>
&lt;ol>
&lt;li>&lt;strong>Spatial awareness on the globe&lt;/strong>&lt;/li>
&lt;li>&lt;strong>Natural resources awareness&lt;/strong>&lt;/li>
&lt;/ol>
&lt;p>The first will hugely impact your world of view because you were considering only the continent in which you are inhabiting and not the world as a whole. The second is complementary to the first one for understanding why some places are really important to the global market.&lt;/p>
&lt;h1 id="how-you-should-study-the-world-map">How you should study the world map?&lt;/h1>
&lt;p>There is much software out there, I prepared this program of application to use that works kinda like an intensive &lt;strong>memorization&lt;/strong> course of maps for complete beginners.&lt;/p>
&lt;p>Let’s try to attack the first point, we want to gain awareness about where the countries are placed, and possibly where their capital is also placed.&lt;/p>
&lt;p>The first software you will use is &lt;a href="https://www.google.com/maps" target="_blank" rel="noopener">Google Maps&lt;/a>, this was obvious but it is essential for exploring in-depth the countries and cities that you are going to study with other software. Many of these are android apps and are developed by Andrey Solovyev (&lt;a href="https://asmolgam.com/" target="_blank" rel="noopener">this&lt;/a> is the blog of all his games), except the last one which is a deck for &lt;a href="https://apps.ankiweb.net/" target="_blank" rel="noopener">Anki&lt;/a> (if you don’t know what is Anki, you should read &lt;a href="https://blog.cambridgecoaching.com/what-is-anki-and-how-it-transforms-your-mcat-studying" target="_blank" rel="noopener">this&lt;/a> article by Michael Owen on &lt;strong>active recall&lt;/strong>, and &lt;a href="https://fs.blog/spacing-effect/" target="_blank" rel="noopener">this&lt;/a> from Farnam Street for &lt;strong>spaced repetition&lt;/strong>).&lt;/p>
&lt;p>I put there an ordered list of the applications I suggest respecting the ordering to have a better learning experience.&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://play.google.com/store/apps/details?id=com.asmolgam.maps" target="_blank" rel="noopener">All maps quiz&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://play.google.com/store/apps/details?id=com.asmolgam.flags" target="_blank" rel="noopener">World flags quiz&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://play.google.com/store/apps/details?id=com.asmolgam.capitals" target="_blank" rel="noopener">World capitals quiz&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://ankiweb.net/shared/info/2109889812" target="_blank" rel="noopener">Ultimate Geography v5.1 Anki Deck&lt;/a>&lt;/li>
&lt;/ol>
&lt;p>First, install the map quizzes on the smartphone and Google Maps on the PC and now I explain to you why. Use the application and complete all the levels, in each application of Solovyev you have some stars to complete, you can complete them by completing various quizzes for each section. In all applications, the world is divided by continents, which is a big plus for the learning process, I highly recommend studying by continents from the easiest to the hardest.&lt;/p>
&lt;p>The hardest is a subjective thing, probably are just the most distant continent from you 😀.&lt;/p>
&lt;p>The first rush you are doing with the application to each new country you see move to Google Maps and check the neighborhood, try to remember which are the neighbors of the country you studied without looking at the map. If possible, read something about this country, this will help create a model of the country in the brain. Something that you could read about the country is :&lt;/p>
&lt;p>Language
Which kind of politics
History
Food
Religion
Music
Tradition
Art
Architecture
This is a &lt;em>&lt;strong>really important step to do at the start&lt;/strong>&lt;/em>, because this is a &lt;em>learning&lt;/em> process, and after that, the rest of the applications we will use are for &lt;em>&lt;strong>memorization&lt;/strong>&lt;/em>, and you memorize much better once you learn something more about what we are talking instead of just memorizing it like a phone number.&lt;/p>
&lt;p>For the flags application, there is nothing much to say, some flags are really similar and you should study these particular cases, check &lt;a href="https://www.britannica.com/list/flags-that-look-alike" target="_blank" rel="noopener">this&lt;/a> link. Study these &lt;strong>corner cases&lt;/strong> (visualize with closed eyes and spelling their differences should help) and you should be fine for the quiz.&lt;/p>
&lt;p>The last quiz could be the hardest, in my case it’s hard to associate names with other names and memorize them, thanks to this application it becomes easier because there are some images of the country. Of course, for a real study of this country, if you just know the name could be useless, you should try to integrate some notes for better learning. But this isn’t always possible for everybody, so you should just try to memorize it and hope that someday you will reuse it.&lt;/p>
&lt;p>The last step (4) is the &lt;em>real&lt;/em> killer of this study, you are using pure &lt;em>&lt;strong>active recall&lt;/strong>&lt;/em>, there are no multiple selections and there are no letters for writing the answer. You have just to speak out loud (&lt;em>or in your mind&lt;/em>) the answer and then check if it is correct. Thanks to &lt;strong>spatial repetition&lt;/strong> and how the application is tuned you will have more time for practicing harder questions. This Anki Deck contains everything:&lt;/p>
&lt;ul>
&lt;li>Oceans and seas&lt;/li>
&lt;li>Continents&lt;/li>
&lt;li>Maps&lt;/li>
&lt;li>Capitals&lt;/li>
&lt;li>Territories (currently updated and in case of error anyone can propose a solution on the &lt;a href="https://github.com/anki-geo/ultimate-geography" target="_blank" rel="noopener">GitHub repository&lt;/a>)&lt;/li>
&lt;/ul>
&lt;p>For the deck there is a filtered deck feature to focus your study on a subset of cards, for instance, you would like to study all the Europe first.&lt;/p>
&lt;h2 id="how-about-resources">How about resources?&lt;/h2>
&lt;p>We want to learn also how world resources are distributed, this is a hard thing to do. There are no applications but many online resources that we can follow for having an idea of how the world resources are subdivided in 2022.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.investopedia.com/articles/markets-economy/090516/10-countries-most-natural-resources.asp" target="_blank" rel="noopener">10 Countries With the Most Natural Resources&lt;/a> from Investopedia.&lt;/li>
&lt;li>&lt;a href="https://www.mapsofworld.com/thematic-maps/natural-resources-maps/" target="_blank" rel="noopener">Natural Resources Maps&lt;/a> from MoW (Maps of World) which is under MapSherpa (Canada, Ottawa) a Map Distributor. The CEO (and Product Owner) is Dave McIlhagga got a BA in Geography and the company got founded in 1998 (24 years today 30/09/2022).&lt;/li>
&lt;li>A &lt;a href="https://education.nationalgeographic.org/resource/resource-library-distribution-natural-resources/" target="_blank" rel="noopener">collection&lt;/a> of posts from Natural Geographic.&lt;/li>
&lt;/ul>
&lt;h1 id="the-true-size-of-the-countries-on-the-map">The true size of the countries on the map&lt;/h1>
&lt;p>What is shown is not the true size of the countries, there is a polar distortion that occurs in the countries since the flattened map that we usually see is taken from the globe and flattened. For checking the real-world size of a map you should go on &lt;a href="https://www.thetruesize.com/" target="_blank" rel="noopener">thetruesize.com&lt;/a>, select a country and move around to see the distortion from the poles with respect to the equator.&lt;/p>
&lt;p>What is the next step in learning geography?
Is not over yet, the next step for deepening our learning is to learn the internal regions of the countries that we previously learned about. Also, an important part is the culture of these countries that now we know, you should spend most of the time studying this.&lt;/p>
&lt;p>The aim of this post is to lay the &lt;em>groundwork&lt;/em> for those who didn’t have it in elementary school (I’m sure a great many of us won’t) and move up from it.&lt;/p>
&lt;p>These will serve to give a sense of what is being talked about when dealing with the topics of geopolitics, current affairs, etc.&lt;/p>
&lt;p>I hope it can be useful, please leave a comment if there are any problems with this post or information that can be added, as this resource could be reused over time as geography through changes over the years, in its majority, passes the &lt;a href="https://fs.blog/reading/" target="_blank" rel="noopener">test of time&lt;/a>.&lt;/p></description></item><item><title>CUDA Ray Tracer</title><link>https://manuelpagliuca.github.io/project/rt/</link><pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate><guid>https://manuelpagliuca.github.io/project/rt/</guid><description>&lt;p>GPU Computing Course, July 2021, M.Sc. in Computer Science @UniMi&lt;/p>
&lt;h2 id="about-the-project">About the project&lt;/h2>
&lt;p>During the course of &lt;strong>GPU Computing&lt;/strong> I decided to implement my old version of the Ray Tracer (based on the
&lt;em>Ray Tracing in One
Weekend&lt;/em> from
&lt;a href="https://raytracing.github.io/books/RayTracingInOneWeekend.html" target="_blank">Peter Shirley&lt;/a>
)
on &lt;strong>CUDA&lt;/strong>. In
&lt;a href="https://manuelpagliuca.github.io/uploads/GPU_COMPUTING___RAY_TRACER.pdf" target="_blank">this&lt;/a>
paper I compared
the two Ray Tracers underlining the
huge differences in rendering speed (even without achieving the best warp efficiency).&lt;br>&lt;br>
For the comparison I used the same scene in both the implementation composed by 8 different spheres with
different
materials between &lt;em>lambertian&lt;/em>, &lt;em>metal&lt;/em> and &lt;em>dielectrics&lt;/em>. I highly recommend to check the comparisons
and metrics at the end of the paper, the GitHub repository is at
&lt;a href="https://github.com/manuelpagliuca/Ray-Tracer-CUDA" target="_blank">this&lt;/a>
link if you want to see some
render just download
&lt;a href="https://manuelpagliuca.github.io/uploads/GPU_COMPUTING_RENDERS.zip">this&lt;/a>
zip.&lt;/p></description></item><item><title>Deferred renderer</title><link>https://manuelpagliuca.github.io/project/render/</link><pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate><guid>https://manuelpagliuca.github.io/project/render/</guid><description>&lt;p>Real-Time Graphics Programming Course, July 2021, M.Sc. in Computer Science @UniMi&lt;/p>
&lt;h2 id="about-the-project">About the project&lt;/h2>
&lt;p>This was a project I made for the course of Real-time Graphics Programming. The course provided extensive knowledge about real-time computer graphics (you can check the
&lt;a href="https://manuelpagliuca.github.io/uploads/Appunti_RTGP.pdf" target="_blank">notes&lt;/a>
I took). At the end of the course, in addition to an oral exam, there was a project related to graphic programming to be developed with OpenGL. I asked Prof. Gadia if there was the possibility of developing it with Vulkan, he granted me the possibility to take this extra-step, it was very tiring but fruitful from the point of view of learning.&lt;/p>
&lt;p>The project consists in a deferred renderer to improve the overall efficiency of the application in the usage of lights. The scene is composed of three models of the same character, a floor and twenty lights (whose movement and color can be modified), there is the
&lt;a href="https://manuelpagliuca.github.io/uploads/DEFERRED_RENDERING___RTGP.pdf" target="_blank">notes&lt;/a>
containing the various metrics obtained using a different number of lights. The GitHub repository is accessible at
&lt;a href="https://github.com/manuelpagliuca/Vulkan-Deferred-Renderer" target="_blank">this&lt;/a>
link.&lt;/p></description></item><item><title>Fix-It, Stream processing on event-driven system for managing public disservices</title><link>https://manuelpagliuca.github.io/project/fix-it/</link><pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate><guid>https://manuelpagliuca.github.io/project/fix-it/</guid><description>&lt;p>Bachelor&amp;rsquo;s Thesis, December 2019, B.Sc. in Computer Science @UniUPO&lt;/p>
&lt;h2 id="about-the-thesis">About the thesis&lt;/h2>
&lt;p>
&lt;figure id="figure-how-the-flags-are-shown-on-the-map">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="How the flags are shown on the map." srcset="
/project/fix-it/img_hu4a47e7bb555165f3249c1881edac94ca_100119_b37034bddf09116b1976a55737d309a8.webp 400w,
/project/fix-it/img_hu4a47e7bb555165f3249c1881edac94ca_100119_f2bfcd2b8ef27eb87f80159d60305248.webp 760w,
/project/fix-it/img_hu4a47e7bb555165f3249c1881edac94ca_100119_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://manuelpagliuca.github.io/project/fix-it/img_hu4a47e7bb555165f3249c1881edac94ca_100119_b37034bddf09116b1976a55737d309a8.webp"
width="368"
height="613"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption data-pre="Figure&amp;nbsp;" data-post=":&amp;nbsp;" class="numbered">
How the flags are shown on the map.
&lt;/figcaption>&lt;/figure>
The complete title of the thesis is &lt;em>&amp;ldquo;Fix-it : Stream processing on event-driven system for
managing public disservices&amp;rdquo;&lt;/em>. The project itself consist in developing an &lt;strong>E.D.A.&lt;/strong> (Event-Driven Application)
system that will work on a mobile application called &amp;ldquo;&lt;strong>Fix-it&lt;/strong>&amp;rdquo;, which is developed using Android
Studio. The system is implemented with &lt;strong>Google Firebase&lt;/strong> and &lt;strong>Apache Kafka&lt;/strong> (stream processing).
Different technologies involved in the implementation of this project like REST API, Stream Processing and
Publisher-Subscribe pattern.&lt;/p>
&lt;p>The project was developed only by just two guys, we used the concepts of the Agile Manifesto to design our workflow, everything was organized with a Kanban Board on Trello so that we could work consistently by breaking the work down into small parts.&lt;/p>
&lt;p>The whole thesis is downloadable as PDF
&lt;a href="https://manuelpagliuca.github.io/uploads/Manuel_Pagliuca_Tesi.pdf" target="_blank">here&lt;/a>
, was
written using LaTeX on Overleaf, the Abstract is downloadable
&lt;a href="https://manuelpagliuca.github.io/uploads/Abstract.pdf" target="_blank">here&lt;/a>
.
I attained a presentation of my thesis on Google Meet due to COVID-19, and I talked about my
work using these
&lt;a href="https://manuelpagliuca.github.io/uploads/Slides.pdf" target="_blank">slides&lt;/a>
. The project was realized under the
supervision of the Prof. &lt;a href="https://upobook.uniupo.it/davide.cerotti">Davide Cerotti&lt;/a>.&lt;/p></description></item><item><title>L-system in Unity</title><link>https://manuelpagliuca.github.io/project/l-system/</link><pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate><guid>https://manuelpagliuca.github.io/project/l-system/</guid><description>&lt;p>Artificial Intelligence for Videogames course, July 2022, M.Sc. in Computer Science @UniMi&lt;/p>
&lt;h2 id="about-the-project">About the project&lt;/h2>
&lt;p>This is a project for the course of A.I. for VideoGames at University of Milan, A.Y. 2021/2022. The aim of the project is to implement a Lindenmayer system for procedural generation of tree using discrete distributions (pseudo-random integers) for enhancing the believability of the project.&lt;/p>
&lt;center>&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/luaC1rPKbKg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>&lt;/center>
Check the YouTube video for check how the application works while listening to a synthetic explanation. If you want to look at the LateX report, just click
&lt;a href="https://manuelpagliuca.github.io/uploads/L_SYSTEM_AI4V_REPORT.pdf">this link&lt;/a>
. You are invited to send a pull request to the GitHub
&lt;a href="https://github.com/manuelpagliuca/l-system">repository&lt;/a>
.</description></item><item><title>Pain Recognition - Dataset analysis and experimental validation</title><link>https://manuelpagliuca.github.io/project/pain-recognition/</link><pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate><guid>https://manuelpagliuca.github.io/project/pain-recognition/</guid><description>&lt;p>Affective Computing and Natural Interaction courses, Jan 2023, M.Sc. in Computer Science @UniMi&lt;/p>
&lt;h2 id="about-the-project">About the project&lt;/h2>
&lt;p>This is a unified project for the courses Affective Computing and Natural Interaction at &lt;a href="https://phuselab.di.unimi.it/" target="_blank" rel="noopener">PhuseLab&lt;/a>, University of Milan, A.Y. 2021/2022.&lt;/p>
&lt;p>The aim of this project is to test the accuracy of early and late fusion approaches on a multi-modal dataset to classify the presence of pain in patients. Participants were subjected to an external heat-pain stimulus through a physical device.&lt;/p>
&lt;p>Their facial expressions and biophysical signals were recorded using cameras and the application of electrodes, then features were extracted. The descriptors came from two different modalities and will be combined by testing both fusion approaches. Finally, classifications and accuracy estimates were made, based on which it was possible to determine that early fusion is the most accurate approach for the dataset considered.&lt;/p>
&lt;ul>
&lt;li>For more information about the project download the &lt;a href="https://manuelpagliuca.github.io/uploads/Pain_Detection_Manuel_Pagliuca_AC_NI_2022.pdf">report&lt;/a>.&lt;/li>
&lt;/ul>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/diagram.jpg" alt="Diagram" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Pain stimulation occurs in patients through electrostimulators applied to the wrists. When this experiment is performed different bio-potential signals (GSR, EMG, &amp;hellip;) and facial expressions are recorded through (through a video camera).&lt;/p>
&lt;p>The analysis phase involves extracting features from the video signals through computer vision techniques. The features involved are Euclidean distances on particular facial landmarks and gradients on 5 regions of the face.&lt;/p>
&lt;p>Once the biopotential signals and video features are ready, fusion techniques are used to perform classification.&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Early fusion&lt;/strong> involves fusing signals and video features a priori concerning classification. Then train the classifier on the combined inputs.&lt;/li>
&lt;li>&lt;strong>Late fusion&lt;/strong> involves training three classifiers (of the same type) on different inputs (ECG, GSR, and video), then for each sample in the testing set its prediction is calculated with all three classifiers. The majority prediction is considered; if that prediction coincides with the &lt;em>ground truth&lt;/em>, then that prediction is considered correct.&lt;/li>
&lt;/ul>
&lt;p>The classifier used in this project was &lt;em>Support Vector Machines&lt;/em>.&lt;/p>
&lt;h3 id="video-feature-extraction">Video feature extraction&lt;/h3>
&lt;h2 id="tools">Tools&lt;/h2>
&lt;ul>
&lt;li>IntelliJ IDEA and Python for developing the project application.&lt;/li>
&lt;li>Microsoft Excel for working with the &lt;code>.csv&lt;/code> files.&lt;/li>
&lt;li>&lt;a href="https://ieeexplore.ieee.org/document/6617456" target="_blank" rel="noopener">BioVid&lt;/a> dataset.&lt;/li>
&lt;/ul>
&lt;h2 id="dependencies">Dependencies&lt;/h2>
&lt;ul>
&lt;li>OpenCV&lt;/li>
&lt;li>MediaPipe&lt;/li>
&lt;li>Sk-learn&lt;/li>
&lt;li>Numpy&lt;/li>
&lt;/ul>
&lt;h2 id="computer-vision-techniques">Computer vision techniques&lt;/h2>
&lt;p>The computer vision techniques used were for the extraction of facial distances, gradients of facial folds, and head position.&lt;/p>
&lt;h3 id="facial-distances-and-head-pose-estimation">Facial distances and head pose estimation&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/facial_distances.gif" alt="Facial Distances" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="gradient-for-face-folds">Gradient for face folds&lt;/h3>
&lt;p>Gradients allow changes in regions of the face to be assessed. An arithmetic average of pixel values in these regions is calculated.
This average is again weighted by the number of frames in the video window(which in the dataset was 5 seconds).&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/facial_gradients.gif" alt="Facial Gradients" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="switch-button">Switch button&lt;/h3>
&lt;p>There is a debug branch called &lt;code>cv-features&lt;/code> in this repository where you can try computer vision systems directly with your computer camera. Using the tab key you can enable and disable debugging for gradients.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/switch.gif" alt="Switch" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h2 id="ideas-for-future-extensions">Ideas for future extensions&lt;/h2>
&lt;ul>
&lt;li>Calculate the gradient only when the pain stimulus is activated and not over the entire window.&lt;/li>
&lt;li>&amp;hellip;&lt;/li>
&lt;/ul></description></item><item><title>SETA - SElf-driving TA-xi service</title><link>https://manuelpagliuca.github.io/project/seta/</link><pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate><guid>https://manuelpagliuca.github.io/project/seta/</guid><description>&lt;p>Distributed and Pervasive Systems courses, Jun 2022, M.Sc. in Computer Science @UniMi&lt;/p>
&lt;h2 id="about-the-project">About the project&lt;/h2>
&lt;p>Project for the course of &amp;ldquo;Distributed and Pervasive Systems&amp;rdquo; A.A. 2021/2022 for M.Sc.&amp;rsquo;s in Computer Science.&lt;/p>
&lt;p>The objective of the project is to design and develop SETA (Self-driving TAxi service), a
Self-driving &lt;em>peer-to-peer&lt;/em> taxi system for citizens of a smart city. The systems run on a centralized MQTT server which manages the taxis, they are able to communicate with each other via gRPC to ensure access to the resource.&lt;/p>
&lt;h2 id="dev-tools--languages">Dev Tools &amp;amp; Languages&lt;/h2>
&lt;h3 id="languages">Languages&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://www.oracle.com/java/technologies/javase/jdk18-archive-downloads.html" target="_blank" rel="noopener">Java SDK 18.0.2&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="technologies">Technologies&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://grpc.io/" target="_blank" rel="noopener">gRPC&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://mqtt.org/" target="_blank" rel="noopener">MQTT&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Representational_state_transfer" target="_blank" rel="noopener">REST API&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://developers.google.com/protocol-buffers" target="_blank" rel="noopener">Protocol Buffers&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="tools">Tools&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://www.jetbrains.com/idea/download/?section=mac" target="_blank" rel="noopener">IntelliJ IDEA&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/jgraph/drawio-desktop/releases" target="_blank" rel="noopener">draw.io&lt;/a> for drawing diagrams&lt;/li>
&lt;li>Git &amp;amp; GitHub as versioning system&lt;/li>
&lt;/ul>
&lt;p>Within this README are different conceptual diagrams that broadly define the general operation of the system, distributed algorithms, and synchronization procedures.&lt;/p>
&lt;p>These diagrams do not rigidly follow any model as they are simple and extensively commented.&lt;/p>
&lt;h3 id="guidelines">Guidelines&lt;/h3>
&lt;ul>
&lt;li>Rhombuses correspond to flow controls.&lt;/li>
&lt;li>Rectangles to of operations/procedures.&lt;/li>
&lt;li>Green circles are collection points.&lt;/li>
&lt;li>Rectangle colors stand for an object belonging to a certain class (so if there are multiple rectangles of the same color, they are multiple instances of the same class).&lt;/li>
&lt;li>White circles correspond to processes (used in diagrams for distributed algorithms).&lt;/li>
&lt;li>Gray circles correspond to threads (used in diagrams for synchronization).&lt;/li>
&lt;/ul>
&lt;h2 id="general-functioning-of-the-project">General functioning of the project&lt;/h2>
&lt;p>This is an outline of general operation of the system, it corresponds to what is required in the assignment delivery &lt;a href="Project_DPS_2022___SETA.pdf">document&lt;/a>.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/general_scheme.png" alt="General scheme" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h2 id="distributed-algorithms-diagrams">Distributed algorithms diagrams&lt;/h2>
&lt;h3 id="ricart--agrawala-algorithm-for-mutual-exclusion">Ricart &amp;amp; Agrawala algorithm for mutual exclusion&lt;/h3>
&lt;p>The algorithm was developed for guarantee the mutual exclusion to a critical section between multiple processes in a distributed system.&lt;/p>
&lt;p>The timestamps of the messages are sent in broadcast (in parallel) through the gRPC call &lt;code>coordinateRechargeStream()&lt;/code>. The logical clock synchronization is guaranteed through &lt;strong>Lamport&amp;rsquo;s algorithm&lt;/strong>.&lt;/p>
&lt;p>Let&amp;rsquo;s consider the following diagram, the nodes in red want to access to the critical section, while the other nodes are doing anything else.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/ricart_agrawala_1.png" alt="Ricart &amp;amp;amp; Agrawala 1" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>More in depth in the first phase (in which the requests are parallelized) the processes will build their lists of dependent nodes. These lists will contain all the nodes which got a smaller timestamp relative to their.&lt;/p>
&lt;p>A node will be able to enter a critical section (&lt;em>i.e.&lt;/em>, in this project is the recharging operation) if it receives the ACKs from all the other nodes. If this doesn&amp;rsquo;t happens it will have to wait the residual ACKs.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/ricart_agrawala_2.png" alt="Ricart &amp;amp;amp; Agrawala 2" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Once that a node has finished with the recharging operation, it will sends an ACK message to the taxi of his list/queue. The first taxis who will fill the number of attended ACKs will access the critical section, and then story repeats.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/ricart_agrawala_3.png" alt="Ricart &amp;amp;amp; Agrawala 3" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="ride-election-algorithm">Ride election algorithm&lt;/h3>
&lt;p>The SETA process generates two rides each 5 seconds on a random district, these two rides are posted on the respective topic of the district. Each taxi is subscribed only on the topic of the district in which it currently belongs.&lt;/p>
&lt;p>For simplicity let&amp;rsquo;s assume only one ride (the ride 5) to be published from the SETA process on the first district. All the processes which are subscribed to this topic (inside the green circle) will receive the message for the ride 5.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/ride_election_1.png" alt="Ride Election 1" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>An election mechanism will start through the gRPC call &lt;code>coordinateRideStream()&lt;/code>, the request will be performed in broadcast (also to taxi out from district 1) and they will be executed in parallel. The request will contain the &lt;em>Euclidean distance to the starting point&lt;/em>, the &lt;em>battery levels&lt;/em> and the &lt;em>ID&lt;/em> of taxi which is sending the request.&lt;/p>
&lt;p>For sake of simplicity we are seeing the evolution of the algorithm only from the point of view of the process 1.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/ride_election_2.png" alt="Ride Election 2" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Let&amp;rsquo;s also assume that the process 1 is the process with the smallest distance from the starting point of the ride. Essentially, this means that the taxi who receives the request will all answer with an ACK (this means that they got a worst distance, battery or grater ID respect to process 1), only in this case the process 1 will achieve the consensus.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/ride_election_3.png" alt="Ride Election 3" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Now the process 1 can execute the ride 5, before it even pass to the local execution of the ride, it publish a message containing the ride 5 on the &lt;code>seta/smartcity/completed&lt;/code> topic. This will allow to stop recycling this message (we will see what is it below) and also making know to the taxi which ride ignore since it is already taken.&lt;/p>
&lt;p>This because all the taxi will have a local list containing all the completed rides taken from the topic, in this way they know which ride to avoid.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/ride_election_4.png" alt="Ride Election 4" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h4 id="ride-recycling">Ride recycling&lt;/h4>
&lt;p>There is a system that enforces the recycling of runs, each run that is generated on the topics is embedded within the relative queue of the district. The priority of the queues is based on the order (run ID) of run generation, so older runs will be preferred.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/ride_recycling.png" alt="Ride Recycling" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h2 id="conceptual-schemes-of-synchronizations">Conceptual schemes of synchronizations&lt;/h2>
&lt;h3 id="user-input">User input&lt;/h3>
&lt;p>Command entry by users is handled by two threads. One thread for reading and executing the commands entered (&lt;strong>CLI&lt;/strong>, &lt;em>Command Line Interface&lt;/em>), and one thread for controlling the &lt;em>input stream&lt;/em> (&lt;strong>Input Checker&lt;/strong>).&lt;/p>
&lt;p>This approach is designed in such a way as to avoid &amp;ldquo;&lt;em>busy waiting&lt;/em>&amp;rdquo; phenomena. There is a shared &lt;em>dummy object&lt;/em> between the two objects; the thread for the CLI waits to receive an encoding on this object, notification will be sent by the Input Checker when the presence of user input is detected.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/busy_waiting.png" alt="Busy Waiting" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="recharge-operation">Recharge operation&lt;/h3>
&lt;p>There is a thread that monitors cab battery levels (&lt;strong>Recharge Thread&lt;/strong>), to avoid &amp;ldquo;&lt;em>busy waiting&lt;/em>&amp;rdquo; phenomena a &lt;em>dummy object&lt;/em> is shared between this thread and the &lt;strong>MQTT module&lt;/strong>.&lt;/p>
&lt;p>The recharge thread is initially waiting and will check the battery levels only after receiving the notification on the shared &lt;em>dummy object&lt;/em>.&lt;/p>
&lt;p>As we know, the MQTT module receives races message for it&amp;rsquo;s own district, and its callbacks can in turn call methods (which basically function like threads). Upon completion of the function that takes care of the run we notify the &lt;em>dummy object&lt;/em> through &lt;code>notify()&lt;/code>.&lt;/p>
&lt;p>This way a check of battery levels will be made after a run is finished. The charging procedure will only be started if the battery levels are below 30 percent.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/recharge_synchronization.png" alt="Synchronization of recharging spot" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="local-statistics">Local statistics&lt;/h3>
&lt;p>The collection and submission of local statistics involves different agents :&lt;/p>
&lt;ul>
&lt;li>A &lt;strong>PM10 simulator&lt;/strong> that generates random measurements of pollution levels at a random cadence.&lt;/li>
&lt;li>A &lt;strong>Pollution Buffer&lt;/strong> which is a data structure used for the collection and self-management (&lt;em>sliding window&lt;/em> technique) of measurements generated by the PM10 simulator.&lt;/li>
&lt;li>A thread for reading the PM10 measurements buffered in the Pollution Buffer, with addition of the other local statistics (&lt;em>total traveled km, battery levels, accomplished runs, &amp;hellip;&lt;/em>) and subsequent sending on the administrator server via POST request (&lt;strong>Local Stats Thread&lt;/strong>).&lt;/li>
&lt;li>A thread to ensure local statistics are sent every 15 seconds (&lt;strong>Enable Data Send Thread&lt;/strong>).&lt;/li>
&lt;/ul>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/localstats_synchronization.png" alt="Synchronization of local statistics" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>The reading of measurements is done by the Local Stats Thread, the latter though is governed by the operation of the Pollution Buffer&amp;rsquo;s internal data structure.&lt;/p>
&lt;p>Once the array of measurements is read, its average is calculated. Then a data structure is created that will contain both this average of measurements and the other local statistics :&lt;/p>
&lt;ul>
&lt;li>Total traveled kilometers&lt;/li>
&lt;li>Battery levels&lt;/li>
&lt;li>Total accomplished runs&lt;/li>
&lt;/ul>
&lt;p>Every fifteen seconds you will be able to send this data structure to the administrator server via POST, to ensure this you use a thread (Enable Data Thread) that sets a boolean (initialized to false) to true.&lt;/p>
&lt;p>That boolean variable will be checked by the Local Stats Thread, if true, then the POST request will be executed.&lt;/p>
&lt;p>Then the flag will be set to false again, and you will have to wait 15 seconds again for it to be reactivated.&lt;/p>
&lt;h4 id="sliding-window">Sliding window&lt;/h4>
&lt;p>The Pollution Buffer presents a method that is constantly called at an unknown time by the PM10 simulator. The Pollution Buffer internal structure consists of a &lt;em>sliding window&lt;/em> of 50% of size 8 (each element is a PM10 measurements).&lt;/p>
&lt;p>Once the maximum capacity of our internal data structure is reached, then I can guarantee that it will be read by the Local Stats Thread. The read operation involves a left shift of 50% of the elements (&lt;em>i.e.,&lt;/em> 4 elements), henceforth the elements added by the PM10 simulator will be allocated starting from the fifth.
When the last element (the eighth) is added again, then a new reading of the sliding window can be performed again.&lt;/p>
&lt;p>In this way the various sliding windows that are read will share four elements, &lt;em>i.e.,&lt;/em> the sliding window of iteration &lt;code>t-1&lt;/code> will have the last four elements equal to the first four elements of the sliding window at time &lt;code>t&lt;/code>.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://manuelpagliuca.github.io/uploads/sliding_window.png" alt="Sliding Window" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>Subdivision of surfaces</title><link>https://manuelpagliuca.github.io/project/geometry/</link><pubDate>Sun, 27 Jun 2021 00:00:00 +0000</pubDate><guid>https://manuelpagliuca.github.io/project/geometry/</guid><description>&lt;p>Computational Geometry Course, March 2021, M.Sc. in Computer Science @UniMi&lt;/p>
&lt;h2 id="about-the-project">About the project&lt;/h2>
&lt;figure id="figure-icosahedron-obtained-with-the-application">
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Icosahedron obtained with the application." srcset="
/project/geometry/img_hu92825ff421db5b452c03fb61016d2789_175632_61a89ba5ff0edc125b01e8b25e2f98da.webp 400w,
/project/geometry/img_hu92825ff421db5b452c03fb61016d2789_175632_5e4e12b5ba32a7e3a372e59919161a64.webp 760w,
/project/geometry/img_hu92825ff421db5b452c03fb61016d2789_175632_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://manuelpagliuca.github.io/project/geometry/img_hu92825ff421db5b452c03fb61016d2789_175632_61a89ba5ff0edc125b01e8b25e2f98da.webp"
width="760"
height="681"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;figcaption data-pre="Figure&amp;nbsp;" data-post=":&amp;nbsp;" class="numbered">
Icosahedron obtained with the application.
&lt;/figcaption>&lt;/figure>
&lt;p>The aims of this project was to study how the tessellation works with simple domains and to
implement the basic logic for triangulate the vertices of simple
objects like cubes and then with more complex like torus, sphere and cylinder.&lt;/p>
&lt;center>&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/tK8yzO6Btho"
title="YouTube video player" frameborder="0"
allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
allowfullscreen>&lt;/iframe>&lt;/center>
For the course project there was also a need to produce a report in the form of &lt;a
href="http://www.mat.unimi.it/users/alzati/Geometria_Computazionale_98-99/apps/trietas/index.html">website&lt;/a>
(fully in &lt;i>italian&lt;/i>) which is hosted from the university's mathematics department &lt;i>Federigo Enriques&lt;/i>. It contains
the theory behind the software, the technique involved, user manual of the application and lot of example videos about the application.
&lt;p>Is possible to download the source code of the project from the &lt;a
href="https://github.com/manuelpagliuca/Computational_Geometry_2021">GitHub Repository&lt;/a> by
following this link. The course was a complete math course and the project was developed using the
&lt;strong>OpenGL&lt;/strong> specification.&lt;/p>
&lt;p>By accessing the &lt;a
href="http://www.mat.unimi.it/users/alzati/Geometria_Computazionale_98-99/corso/autori.html">authors
section&lt;/a> of the course website, is possible to read under my
name a note from the course teacher saying: &lt;br>&lt;br>&lt;/p>
&lt;p>&lt;em>&amp;ldquo;has developed the project related to the triangulation and tessellation of the lateral
surface of some geometric solids obtaining truly amazing visual effects.&amp;rdquo;&lt;/em> - Prof. Alzati&lt;/p></description></item><item><title>Slides</title><link>https://manuelpagliuca.github.io/slides/example/</link><pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate><guid>https://manuelpagliuca.github.io/slides/example/</guid><description>&lt;h1 id="create-slides-in-markdown-with-wowchemy">Create slides in Markdown with Wowchemy&lt;/h1>
&lt;p>&lt;a href="https://wowchemy.com/" target="_blank" rel="noopener">Wowchemy&lt;/a> | &lt;a href="https://wowchemy.com/docs/content/slides/" target="_blank" rel="noopener">Documentation&lt;/a>&lt;/p>
&lt;hr>
&lt;h2 id="features">Features&lt;/h2>
&lt;ul>
&lt;li>Efficiently write slides in Markdown&lt;/li>
&lt;li>3-in-1: Create, Present, and Publish your slides&lt;/li>
&lt;li>Supports speaker notes&lt;/li>
&lt;li>Mobile friendly slides&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="controls">Controls&lt;/h2>
&lt;ul>
&lt;li>Next: &lt;code>Right Arrow&lt;/code> or &lt;code>Space&lt;/code>&lt;/li>
&lt;li>Previous: &lt;code>Left Arrow&lt;/code>&lt;/li>
&lt;li>Start: &lt;code>Home&lt;/code>&lt;/li>
&lt;li>Finish: &lt;code>End&lt;/code>&lt;/li>
&lt;li>Overview: &lt;code>Esc&lt;/code>&lt;/li>
&lt;li>Speaker notes: &lt;code>S&lt;/code>&lt;/li>
&lt;li>Fullscreen: &lt;code>F&lt;/code>&lt;/li>
&lt;li>Zoom: &lt;code>Alt + Click&lt;/code>&lt;/li>
&lt;li>&lt;a href="https://revealjs.com/pdf-export/" target="_blank" rel="noopener">PDF Export&lt;/a>&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="code-highlighting">Code Highlighting&lt;/h2>
&lt;p>Inline code: &lt;code>variable&lt;/code>&lt;/p>
&lt;p>Code block:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="n">porridge&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;blueberry&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">if&lt;/span> &lt;span class="n">porridge&lt;/span> &lt;span class="o">==&lt;/span> &lt;span class="s2">&amp;#34;blueberry&amp;#34;&lt;/span>&lt;span class="p">:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;Eating...&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h2 id="math">Math&lt;/h2>
&lt;p>In-line math: $x + y = z$&lt;/p>
&lt;p>Block math:&lt;/p>
&lt;p>$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p>
&lt;hr>
&lt;h2 id="fragments">Fragments&lt;/h2>
&lt;p>Make content appear incrementally&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">{{% fragment %}} One {{% /fragment %}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{{% fragment %}} **Two** {{% /fragment %}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{{% fragment %}} Three {{% /fragment %}}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Press &lt;code>Space&lt;/code> to play!&lt;/p>
&lt;span class="fragment " >
One
&lt;/span>
&lt;span class="fragment " >
&lt;strong>Two&lt;/strong>
&lt;/span>
&lt;span class="fragment " >
Three
&lt;/span>
&lt;hr>
&lt;p>A fragment can accept two optional parameters:&lt;/p>
&lt;ul>
&lt;li>&lt;code>class&lt;/code>: use a custom style (requires definition in custom CSS)&lt;/li>
&lt;li>&lt;code>weight&lt;/code>: sets the order in which a fragment appears&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h2 id="speaker-notes">Speaker Notes&lt;/h2>
&lt;p>Add speaker notes to your presentation&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-markdown" data-lang="markdown">&lt;span class="line">&lt;span class="cl">{{% speaker_note %}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">-&lt;/span> Only the speaker can read these notes
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="k">-&lt;/span> Press &lt;span class="sb">`S`&lt;/span> key to view
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {{% /speaker_note %}}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Press the &lt;code>S&lt;/code> key to view the speaker notes!&lt;/p>
&lt;aside class="notes">
&lt;ul>
&lt;li>Only the speaker can read these notes&lt;/li>
&lt;li>Press &lt;code>S&lt;/code> key to view&lt;/li>
&lt;/ul>
&lt;/aside>
&lt;hr>
&lt;h2 id="themes">Themes&lt;/h2>
&lt;ul>
&lt;li>black: Black background, white text, blue links (default)&lt;/li>
&lt;li>white: White background, black text, blue links&lt;/li>
&lt;li>league: Gray background, white text, blue links&lt;/li>
&lt;li>beige: Beige background, dark text, brown links&lt;/li>
&lt;li>sky: Blue background, thin dark text, blue links&lt;/li>
&lt;/ul>
&lt;hr>
&lt;ul>
&lt;li>night: Black background, thick white text, orange links&lt;/li>
&lt;li>serif: Cappuccino background, gray text, brown links&lt;/li>
&lt;li>simple: White background, black text, blue links&lt;/li>
&lt;li>solarized: Cream-colored background, dark green text, blue links&lt;/li>
&lt;/ul>
&lt;hr>
&lt;section data-noprocess data-shortcode-slide
data-background-image="/media/boards.jpg"
>
&lt;h2 id="custom-slide">Custom Slide&lt;/h2>
&lt;p>Customize the slide style and background&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-markdown" data-lang="markdown">&lt;span class="line">&lt;span class="cl">{{&lt;span class="p">&amp;lt;&lt;/span> &lt;span class="nt">slide&lt;/span> &lt;span class="na">background-image&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;/media/boards.jpg&amp;#34;&lt;/span> &lt;span class="p">&amp;gt;&lt;/span>}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{{&lt;span class="p">&amp;lt;&lt;/span> &lt;span class="nt">slide&lt;/span> &lt;span class="na">background-color&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;#0000FF&amp;#34;&lt;/span> &lt;span class="p">&amp;gt;&lt;/span>}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{{&lt;span class="p">&amp;lt;&lt;/span> &lt;span class="nt">slide&lt;/span> &lt;span class="na">class&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;my-style&amp;#34;&lt;/span> &lt;span class="p">&amp;gt;&lt;/span>}}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h2 id="custom-css-example">Custom CSS Example&lt;/h2>
&lt;p>Let&amp;rsquo;s make headers navy colored.&lt;/p>
&lt;p>Create &lt;code>assets/css/reveal_custom.css&lt;/code> with:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-css" data-lang="css">&lt;span class="line">&lt;span class="cl">&lt;span class="p">.&lt;/span>&lt;span class="nc">reveal&lt;/span> &lt;span class="nt">section&lt;/span> &lt;span class="nt">h1&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">.&lt;/span>&lt;span class="nc">reveal&lt;/span> &lt;span class="nt">section&lt;/span> &lt;span class="nt">h2&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">.&lt;/span>&lt;span class="nc">reveal&lt;/span> &lt;span class="nt">section&lt;/span> &lt;span class="nt">h3&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">color&lt;/span>&lt;span class="p">:&lt;/span> &lt;span class="kc">navy&lt;/span>&lt;span class="p">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;hr>
&lt;h1 id="questions">Questions?&lt;/h1>
&lt;p>&lt;a href="https://discord.gg/z8wNYzb" target="_blank" rel="noopener">Ask&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://wowchemy.com/docs/content/slides/" target="_blank" rel="noopener">Documentation&lt;/a>&lt;/p></description></item><item><title/><link>https://manuelpagliuca.github.io/admin/config.yml</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://manuelpagliuca.github.io/admin/config.yml</guid><description/></item></channel></rss>